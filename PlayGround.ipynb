{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2610,  0.7873, -0.4855],\n",
      "         [-0.5748,  1.3465, -0.7469],\n",
      "         [-0.4440,  0.7907, -0.4893],\n",
      "         [-0.6069,  0.8014, -0.4553]],\n",
      "\n",
      "        [[-0.4112,  1.2325, -0.7060],\n",
      "         [-0.5622,  1.0576, -0.4181],\n",
      "         [-0.7105,  0.8885, -0.4503],\n",
      "         [-0.4032,  1.0951, -0.6981]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[-1.5373, -0.4889, -1.7618],\n",
      "         [-2.1601, -0.2388, -2.3322],\n",
      "         [-1.6851, -0.4504, -1.7305],\n",
      "         [-1.8330, -0.4247, -1.6814]],\n",
      "\n",
      "        [[-1.9343, -0.2906, -2.2291],\n",
      "         [-1.9751, -0.3552, -1.8310],\n",
      "         [-1.9804, -0.3813, -1.7202],\n",
      "         [-1.8275, -0.3293, -2.1224]]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[[0.2150, 0.6133, 0.1717],\n",
      "         [0.1153, 0.7876, 0.0971],\n",
      "         [0.1854, 0.6374, 0.1772],\n",
      "         [0.1599, 0.6540, 0.1861]],\n",
      "\n",
      "        [[0.1445, 0.7478, 0.1076],\n",
      "         [0.1387, 0.7010, 0.1603],\n",
      "         [0.1380, 0.6830, 0.1790],\n",
      "         [0.1608, 0.7195, 0.1197]]], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.2712, grad_fn=<NllLossBackward>)\n",
      "tensor(7.2712, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear = torch.nn.Linear(n_features, n_classes)\n",
    "\n",
    "    def forward(self, x, flag=True):\n",
    "        x = self.linear(x)\n",
    "        if flag:\n",
    "            print(x)\n",
    "            x = F.log_softmax(x, dim=2)\n",
    "            print(x)\n",
    "            print(F.softmax(x, dim=2))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "n_steps = 2\n",
    "n_classes = 3\n",
    "mb_size = 4\n",
    "n_features = 5\n",
    "\n",
    "net = Net(n_features, n_classes)\n",
    "\n",
    "loss1 = torch.nn.NLLLoss(size_average=False)\n",
    "loss2 = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "x = Variable(torch.rand(n_steps, mb_size, n_features))\n",
    "y = Variable(\n",
    "    torch.LongTensor(np.random.randint(0, n_classes, (n_steps, mb_size))))\n",
    "#print(x)\n",
    "#print(y.view(-1))\n",
    "\n",
    "logits1 = net(x, flag=True).view(-1, n_classes)\n",
    "logits2 = net(x, flag=False).view(-1, n_classes)\n",
    "#print(logits1)\n",
    "loss_val1 = loss1(logits1, y.view(-1))\n",
    "loss_val2 = loss2(logits2, y.view(-1))\n",
    "\n",
    "\n",
    "print(loss_val1)\n",
    "print(loss_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.from_numpy(np.array([[2, 3, 5], [0, 1, 9]], dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 5.],\n",
       "        [0., 1., 9.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.2010e-02, 1.1420e-01, 8.4379e-01],\n",
       "        [1.2335e-04, 3.3531e-04, 9.9954e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 5])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7463, 0.0706, 0.3957, 0.6919, 0.2841, 0.4282, 0.5358, 0.6964,\n",
       "          0.0163, 0.1339, 0.9295, 0.6869, 0.3140, 0.2882, 0.3999, 0.0767,\n",
       "          0.3964, 0.5703, 0.1846, 0.4629],\n",
       "         [0.5438, 0.9678, 0.5508, 0.8550, 0.5939, 0.7174, 0.7270, 0.1823,\n",
       "          0.5730, 0.6263, 0.2587, 0.7510, 0.3463, 0.7777, 0.6522, 0.6844,\n",
       "          0.1930, 0.4917, 0.9384, 0.1322],\n",
       "         [0.5116, 0.9799, 0.7421, 0.7625, 0.1922, 0.3161, 0.9216, 0.3245,\n",
       "          0.1711, 0.4579, 0.3093, 0.3607, 0.1209, 0.3261, 0.9137, 0.9284,\n",
       "          0.3938, 0.6528, 0.9144, 0.5762]],\n",
       "\n",
       "        [[0.3351, 0.0068, 0.5196, 0.9087, 0.1298, 0.2337, 0.8939, 0.4740,\n",
       "          0.2605, 0.1277, 0.1602, 0.0797, 0.7954, 0.8363, 0.3608, 0.4092,\n",
       "          0.8502, 0.3008, 0.2604, 0.5931],\n",
       "         [0.8269, 0.9104, 0.9192, 0.2170, 0.9983, 0.8720, 0.3779, 0.7808,\n",
       "          0.2180, 0.4525, 0.2552, 0.0600, 0.0269, 0.9106, 0.3451, 0.2861,\n",
       "          0.3838, 0.5220, 0.5289, 0.8189],\n",
       "         [0.3593, 0.1738, 0.9887, 0.0322, 0.8541, 0.7108, 0.0666, 0.8798,\n",
       "          0.9817, 0.4416, 0.9069, 0.4453, 0.4294, 0.7734, 0.4476, 0.8828,\n",
       "          0.4288, 0.7396, 0.5531, 0.8551]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(2, 3, 4 * 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
