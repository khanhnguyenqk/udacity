{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Sentiment Analysis Web App\n",
    "## Using PyTorch and SageMaker\n",
    "\n",
    "_Deep Learning Nanodegree Program | Deployment_\n",
    "\n",
    "---\n",
    "\n",
    "Now that we have a basic understanding of how SageMaker works we will try to use it to construct a complete project from end to end. Our goal will be to have a simple web page which a user can use to enter a movie review. The web page will then send the review off to our deployed model which will predict the sentiment of the entered review.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this notebook. You will not need to modify the included code beyond what is requested. Sections that begin with '**TODO**' in the header indicate that you need to complete or implement some portion within them. Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a `# TODO: ...` comment. Please be sure to read the instructions carefully!\n",
    "\n",
    "In addition to implementing code, there will be questions for you to answer which relate to the task and your implementation. Each section where you will answer a question is preceded by a '**Question:**' header. Carefully read each question and provide your answer below the '**Answer:**' header by editing the Markdown cell.\n",
    "\n",
    "> **Note**: Code and Markdown cells can be executed using the **Shift+Enter** keyboard shortcut. In addition, a cell can be edited by typically clicking it (double-click for Markdown cells) or by pressing **Enter** while it is highlighted.\n",
    "\n",
    "## General Outline\n",
    "\n",
    "Recall the general outline for SageMaker projects using a notebook instance.\n",
    "\n",
    "1. Download or otherwise retrieve the data.\n",
    "2. Process / Prepare the data.\n",
    "3. Upload the processed data to S3.\n",
    "4. Train a chosen model.\n",
    "5. Test the trained model (typically using a batch transform job).\n",
    "6. Deploy the trained model.\n",
    "7. Use the deployed model.\n",
    "\n",
    "For this project, you will be following the steps in the general outline with some modifications. \n",
    "\n",
    "First, you will not be testing the model in its own step. You will still be testing the model, however, you will do it by deploying your model and then using the deployed model by sending the test data to it. One of the reasons for doing this is so that you can make sure that your deployed model is working correctly before moving forward.\n",
    "\n",
    "In addition, you will deploy and use your trained model a second time. In the second iteration you will customize the way that your trained model is deployed by including some of your own code. In addition, your newly deployed model will be used in the sentiment analysis web app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Downloading the data\n",
    "\n",
    "As in the XGBoost in SageMaker notebook, we will be using the [IMDb dataset](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "> Maas, Andrew L., et al. [Learning Word Vectors for Sentiment Analysis](http://ai.stanford.edu/~amaas/data/sentiment/). In _Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies_. Association for Computational Linguistics, 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-04 01:48:03--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘../data/aclImdb_v1.tar.gz’\n",
      "\n",
      "../data/aclImdb_v1. 100%[===================>]  80.23M  38.2MB/s    in 2.1s    \n",
      "\n",
      "2019-11-04 01:48:05 (38.2 MB/s) - ‘../data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%mkdir ../data\n",
    "!wget -O ../data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -zxf ../data/aclImdb_v1.tar.gz -C ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparing and Processing the data\n",
    "\n",
    "Also, as in the XGBoost notebook, we will be doing some initial data processing. The first few steps are the same as in the XGBoost example. To begin with, we will read in each of the reviews and combine them into a single input structure. Then, we will split the dataset into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def read_imdb_data(data_dir='../data/aclImdb'):\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for data_type in ['train', 'test']:\n",
    "        data[data_type] = {}\n",
    "        labels[data_type] = {}\n",
    "        \n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            data[data_type][sentiment] = []\n",
    "            labels[data_type][sentiment] = []\n",
    "            \n",
    "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
    "            files = glob.glob(path)\n",
    "            \n",
    "            for f in files:\n",
    "                with open(f) as review:\n",
    "                    data[data_type][sentiment].append(review.read())\n",
    "                    # Here we represent a positive review by '1' and a negative review by '0'\n",
    "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
    "                    \n",
    "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
    "                \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
     ]
    }
   ],
   "source": [
    "data, labels = read_imdb_data()\n",
    "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
    "            len(data['train']['pos']), len(data['train']['neg']),\n",
    "            len(data['test']['pos']), len(data['test']['neg'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've read the raw training and testing data from the downloaded dataset, we will combine the positive and negative reviews and shuffle the resulting records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_imdb_data(data, labels):\n",
    "    \"\"\"Prepare training and test sets from IMDb movie reviews.\"\"\"\n",
    "    \n",
    "    #Combine positive and negative reviews and labels\n",
    "    data_train = data['train']['pos'] + data['train']['neg']\n",
    "    data_test = data['test']['pos'] + data['test']['neg']\n",
    "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
    "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
    "    \n",
    "    #Shuffle reviews and corresponding labels within training and test sets\n",
    "    data_train, labels_train = shuffle(data_train, labels_train)\n",
    "    data_test, labels_test = shuffle(data_test, labels_test)\n",
    "    \n",
    "    # Return a unified training data, test data, training labels, test labets\n",
    "    return data_train, data_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb reviews (combined): train = 25000, test = 25000\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
    "print(\"IMDb reviews (combined): train = {}, test = {}\".format(len(train_X), len(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training and testing sets unified and prepared, we should do a quick check and see an example of the data our model will be trained on. This is generally a good idea as it allows you to see how each of the further processing steps affects the reviews and it also ensures that the data has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexandr \"Sascha\" Luzhin (John Turturro) is a former leading chess player attempting a comeback at an Italy-hosted tournament. His brilliance is unquestioned but his obsession with chess has stunted his growth in all other aspects of his life. Natalia (Emily Watson) is a beautiful heiress who has come to the same resort with her mother, Vera (Geraldine James) to scope out possible marriage partners. Vera leans toward a handsome count but, astonishingly, Natalia is more fascinated by Sascha, whom she met on a walk. Sascha, too, is taken with Natalia and proposes marriage at their second meeting. But, with the concentration that Sascha must give to the chess matches and, with other happenings in his past still causing problems, will he win the heart of Natalia? Oh, and can he become the chess champion, also? This is a lovely film, based on a novel by Nabokov. The acting is amazing, with Watson very fine as the beautiful little rich girl and Turturro utter perfection as the shy, awkward chess enthusiast. James gives quite a nice turn as the overbearing mother and the other cast members are wonderful as well. As for the look of the film, it could not be better. The scenery is of the put-your-eye-out variety, the vintage costumes are gorgeous and the cinematography is deserving of much applause. Yes, the story is unusual and told with the use of flashbacks, at times, making it a film not everyone will appreciate. Then, too, the ending is bittersweet. However, if you love romance, period pieces, great acting, knockout scenery, or the fine art of motion picture creation, don't miss this one. You will be defenseless in resisting its multitude of charms.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_X[100])\n",
    "print(train_y[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in processing the reviews is to make sure that any html tags that appear should be removed. In addition we wish to tokenize our input, that way words such as *entertained* and *entertaining* are considered the same with regard to sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(review):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `review_to_words` method defined above uses `BeautifulSoup` to remove any html tags that appear and uses the `nltk` package to tokenize the reviews. As a check to ensure we know how everything is working, try applying `review_to_words` to one of the reviews in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexandr', 'sascha', 'luzhin', 'john', 'turturro', 'former', 'lead', 'chess', 'player', 'attempt', 'comeback', 'itali', 'host', 'tournament', 'brillianc', 'unquest', 'obsess', 'chess', 'stunt', 'growth', 'aspect', 'life', 'natalia', 'emili', 'watson', 'beauti', 'heiress', 'come', 'resort', 'mother', 'vera', 'geraldin', 'jame', 'scope', 'possibl', 'marriag', 'partner', 'vera', 'lean', 'toward', 'handsom', 'count', 'astonishingli', 'natalia', 'fascin', 'sascha', 'met', 'walk', 'sascha', 'taken', 'natalia', 'propos', 'marriag', 'second', 'meet', 'concentr', 'sascha', 'must', 'give', 'chess', 'match', 'happen', 'past', 'still', 'caus', 'problem', 'win', 'heart', 'natalia', 'oh', 'becom', 'chess', 'champion', 'also', 'love', 'film', 'base', 'novel', 'nabokov', 'act', 'amaz', 'watson', 'fine', 'beauti', 'littl', 'rich', 'girl', 'turturro', 'utter', 'perfect', 'shi', 'awkward', 'chess', 'enthusiast', 'jame', 'give', 'quit', 'nice', 'turn', 'overbear', 'mother', 'cast', 'member', 'wonder', 'well', 'look', 'film', 'could', 'better', 'sceneri', 'put', 'eye', 'varieti', 'vintag', 'costum', 'gorgeou', 'cinematographi', 'deserv', 'much', 'applaus', 'ye', 'stori', 'unusu', 'told', 'use', 'flashback', 'time', 'make', 'film', 'everyon', 'appreci', 'end', 'bittersweet', 'howev', 'love', 'romanc', 'period', 'piec', 'great', 'act', 'knockout', 'sceneri', 'fine', 'art', 'motion', 'pictur', 'creation', 'miss', 'one', 'defenseless', 'resist', 'multitud', 'charm']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Apply review_to_words to a review (train_X[100] or any other review)\n",
    "review_to_words(train_X[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Above we mentioned that `review_to_words` method removes html formatting and allows us to tokenize the words found in a review, for example, converting *entertained* and *entertaining* into *entertain* so that they are treated as though they are the same word. What else, if anything, does this method do to the input?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "`review_to_words` also:\n",
    "- Convert any non word/digit characters to a single empty space.\n",
    "- Convert all character to lower case.\n",
    "- Split review into array of strings by empty spaces.\n",
    "- Remove any english stopwords.\n",
    "- Stem all words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method below applies the `review_to_words` method to each of the reviews in the training and testing datasets. In addition it caches the results. This is because performing this processing step can take a long time. This way if you are unable to complete the notebook in the current session, you can come back without needing to process the data a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cache_dir = os.path.join(\"../cache\", \"sentiment_analysis\")  # where to store cache files\n",
    "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
    "\n",
    "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
    "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
    "    \"\"\"Convert each review to words; read from cache if available.\"\"\"\n",
    "\n",
    "    # If cache_file is not None, try to read from it first\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass  # unable to read from cache, but that's okay\n",
    "    \n",
    "    # If cache is missing, then do the heavy lifting\n",
    "    if cache_data is None:\n",
    "        # Preprocess training and test data to obtain words for each review\n",
    "        #words_train = list(map(review_to_words, data_train))\n",
    "        #words_test = list(map(review_to_words, data_test))\n",
    "        words_train = [review_to_words(review) for review in data_train]\n",
    "        words_test = [review_to_words(review) for review in data_test]\n",
    "        \n",
    "        # Write to cache file for future runs\n",
    "        if cache_file is not None:\n",
    "            cache_data = dict(words_train=words_train, words_test=words_test,\n",
    "                              labels_train=labels_train, labels_test=labels_test)\n",
    "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "    else:\n",
    "        # Unpack data loaded from cache file\n",
    "        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
    "                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
    "    \n",
    "    return words_train, words_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote preprocessed data to cache file: preprocessed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "train_X, test_X, train_y, test_y = preprocess_data(train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data\n",
    "\n",
    "In the XGBoost notebook we transformed the data from its word representation to a bag-of-words feature representation. For the model we are going to construct in this notebook we will construct a feature representation which is very similar. To start, we will represent each word as an integer. Of course, some of the words that appear in the reviews occur very infrequently and so likely don't contain much information for the purposes of sentiment analysis. The way we will deal with this problem is that we will fix the size of our working vocabulary and we will only include the words that appear most frequently. We will then combine all of the infrequent words into a single category and, in our case, we will label it as `1`.\n",
    "\n",
    "Since we will be using a recurrent neural network, it will be convenient if the length of each review is the same. To do this, we will fix a size for our reviews and then pad short reviews with the category 'no word' (which we will label `0`) and truncate long reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Create a word dictionary\n",
    "\n",
    "To begin with, we need to construct a way to map words that appear in the reviews to integers. Here we fix the size of our vocabulary (including the 'no word' and 'infrequent' categories) to be `5000` but you may wish to change this to see how it affects the model.\n",
    "\n",
    "> **TODO:** Complete the implementation for the `build_dict()` method below. Note that even though the vocab_size is set to `5000`, we only want to construct a mapping for the most frequently appearing `4998` words. This is because we want to reserve the special labels `0` for 'no word' and `1` for 'infrequent word'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_dict(data, vocab_size = 5000):\n",
    "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
    "    \n",
    "    # TODO: Determine how often each word appears in `data`. Note that `data` is a list of sentences and that a\n",
    "    #       sentence is a list of words.\n",
    "    \n",
    "    word_count = {} # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    for w in [w for sentence in data for w in sentence]:\n",
    "        if w not in word_count:\n",
    "            word_count[w] = 1\n",
    "        else:\n",
    "            word_count[w] += 1\n",
    "            \n",
    "    word_count = [(w, c) for w, c in word_count.items()]\n",
    "    word_count.sort(key=lambda t:t[1], reverse=True)\n",
    "    \n",
    "    # TODO: Sort the words found in `data` so that sorted_words[0] is the most frequently appearing word and\n",
    "    #       sorted_words[-1] is the least frequently appearing word.\n",
    "    \n",
    "    sorted_words = [w for (w, c) in word_count]\n",
    "    \n",
    "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
    "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): # The -2 is so that we save room for the 'no word'\n",
    "        word_dict[word] = idx + 2                              # 'infrequent' labels\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = build_dict(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What are the five most frequently appearing (tokenized) words in the training set? Does it makes sense that these words appear frequently in the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "The five most frequent words appeared in the training set are: movie, film, one, like, time.\n",
    "\n",
    "It makes sense that 'movie' and 'film' appear the most since these reviews are about movies.\n",
    "The word 'like' is 4th which might suggest that humans tend to use this word when they are positive about a movie.\n",
    "'one' and 'time' might just be used a lot because they're common english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movi', 2), ('film', 3), ('one', 4), ('like', 5), ('time', 6)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Use this space to determine the five most frequently appearing words in the training set.\n",
    "list(word_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `word_dict`\n",
    "\n",
    "Later on when we construct an endpoint which processes a submitted review we will need to make use of the `word_dict` which we have created. As such, we will save it to a file now for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/pytorch' # The folder we will use for storing data\n",
    "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the reviews\n",
    "\n",
    "Now that we have our word dictionary which allows us to transform the words appearing in the reviews into integers, it is time to make use of it and convert our reviews to their integer sequence representation, making sure to pad or truncate to a fixed length, which in our case is `500`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(word_dict, sentence, pad=500):\n",
    "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
    "    INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
    "    \n",
    "    working_sentence = [NOWORD] * pad\n",
    "    \n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "def convert_and_pad_data(word_dict, data, pad=500):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
    "test_X, test_X_len = convert_and_pad_data(word_dict, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick check to make sure that things are working as intended, check to see what one of the reviews in the training set looks like after having been processeed. Does this look reasonable? What is the length of a review in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n",
      "25000\n",
      "25000\n",
      "127\n",
      "500\n",
      "[1363    0]\n"
     ]
    }
   ],
   "source": [
    "# Use this cell to examine one of the processed reviews to make sure everything is working as intended.\n",
    "print(len(train_X_len))\n",
    "print(len(train_X))\n",
    "print(len(test_X_len))\n",
    "print(len(test_X))\n",
    "\n",
    "print(train_X_len[0])\n",
    "print(len(train_X[0]))\n",
    "print(train_X[0][train_X_len[0] - 1:train_X_len[0] + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** In the cells above we use the `preprocess_data` and `convert_and_pad_data` methods to process both the training and testing set. Why or why not might this be a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Why this might be a good idea: to make sure our training and testing data are uniformly transformed. When we deploy our model, we also need to transform the raw input in the same way.\n",
    "\n",
    "Why this might be a bad idea: we chose our padding value based on the training data, for example, by the max value of review length. This value, however, might be different on testing data, and especially, might be different when we deploy our model. To be more generic, any hyper parameter that we chose to process our data with might not hold true on testing and deploying data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Upload the data to S3\n",
    "\n",
    "As in the XGBoost notebook, we will need to upload the training dataset to S3 in order for our training code to access it. For now we will save it locally and we will upload to S3 later on.\n",
    "\n",
    "### Save the processed training dataset locally\n",
    "\n",
    "It is important to note the format of the data that we are saving as we will need to know it when we write the training code. In our case, each row of the dataset has the form `label`, `length`, `review[500]` where `review[500]` is a sequence of `500` integers representing the words in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1) \\\n",
    "        .to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the training data\n",
    "\n",
    "\n",
    "Next, we need to upload the training data to the SageMaker default S3 bucket so that we can provide access to it while training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/sentiment_rnn'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The cell above uploads the entire contents of our data directory. This includes the `word_dict.pkl` file. This is fortunate as we will need this later on when we create an endpoint that accepts an arbitrary review. For now, we will just take note of the fact that it resides in the data directory (and so also in the S3 training bucket) and that we will need to make sure it gets saved in the model directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build and Train the PyTorch Model\n",
    "\n",
    "In the XGBoost notebook we discussed what a model is in the SageMaker framework. In particular, a model comprises three objects\n",
    "\n",
    " - Model Artifacts,\n",
    " - Training Code, and\n",
    " - Inference Code,\n",
    " \n",
    "each of which interact with one another. In the XGBoost example we used training and inference code that was provided by Amazon. Here we will still be using containers provided by Amazon with the added benefit of being able to include our own custom code.\n",
    "\n",
    "We will start by implementing our own neural network in PyTorch along with a training script. For the purposes of this project we have provided the necessary model object in the `model.py` file, inside of the `train` folder. You can see the provided implementation by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mLSTMClassifier\u001b[39;49;00m(nn.Module):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    This is the simple RNN model we will be using to perform Sentiment Analysis.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, embedding_dim, hidden_dim, vocab_size):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Initialize the model by settingg up the various layers.\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[36msuper\u001b[39;49;00m(LSTMClassifier, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\r\n",
      "\r\n",
      "        \u001b[36mself\u001b[39;49;00m.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=\u001b[34m0\u001b[39;49;00m)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.lstm = nn.LSTM(embedding_dim, hidden_dim)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.dense = nn.Linear(in_features=hidden_dim, out_features=\u001b[34m1\u001b[39;49;00m)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.sig = nn.Sigmoid()\r\n",
      "        \r\n",
      "        \u001b[36mself\u001b[39;49;00m.word_dict = \u001b[36mNone\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Perform a forward pass of our model on some input.\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        x = x.t()\r\n",
      "        lengths = x[\u001b[34m0\u001b[39;49;00m,:]\r\n",
      "        reviews = x[\u001b[34m1\u001b[39;49;00m:,:]\r\n",
      "        embeds = \u001b[36mself\u001b[39;49;00m.embedding(reviews)\r\n",
      "        lstm_out, _ = \u001b[36mself\u001b[39;49;00m.lstm(embeds)\r\n",
      "        out = \u001b[36mself\u001b[39;49;00m.dense(lstm_out)\r\n",
      "        out = out[lengths - \u001b[34m1\u001b[39;49;00m, \u001b[36mrange\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(lengths))]\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.sig(out.squeeze())\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize train/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important takeaway from the implementation provided is that there are three parameters that we may wish to tweak to improve the performance of our model. These are the embedding dimension, the hidden dimension and the size of the vocabulary. We will likely want to make these parameters configurable in the training script so that if we wish to modify them we do not need to modify the script itself. We will see how to do this later on. To start we will write some of the training code in the notebook so that we can more easily diagnose any issues that arise.\n",
    "\n",
    "First we will load a small portion of the training data set to use as a sample. It would be very time consuming to try and train the model completely in the notebook as we do not have access to a gpu and the compute instance that we are using is not particularly powerful. However, we can work on a small bit of the data to get a feel for how our training script is behaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# Read in only the first 250 rows\n",
    "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None, nrows=250)\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_sample_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
    "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
    "# Build the dataloader\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Writing the training method\n",
    "\n",
    "Next we need to write the training code itself. This should be very similar to training methods that you have written before to train PyTorch models. We will leave any difficult aspects such as model saving / loading and parameter loading until a little later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # TODO: Complete this train method to train the model provided.\n",
    "            model.zero_grad()\n",
    "            y = model(batch_X)\n",
    "            \n",
    "            loss = loss_fn(y, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.data.item()\n",
    "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposing we have the training method above, we will test that it is working by writing a bit of code in the notebook that executes our training method on the small sample training set that we loaded earlier. The reason for doing this in the notebook is so that we have an opportunity to fix any errors that arise early when they are easier to diagnose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, BCELoss: 0.6905032753944397\n",
      "Epoch: 2, BCELoss: 0.6819243669509888\n",
      "Epoch: 3, BCELoss: 0.6740914106369018\n",
      "Epoch: 4, BCELoss: 0.6649889469146728\n",
      "Epoch: 5, BCELoss: 0.6534773707389832\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from train.model import LSTMClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(32, 100, 5000).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "train(model, train_sample_dl, 5, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct a PyTorch model using SageMaker we must provide SageMaker with a training script. We may optionally include a directory which will be copied to the container and from which our training code will be run. When the training container is executed it will check the uploaded directory (if there is one) for a `requirements.txt` file and install any required Python libraries, after which the training script will be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Training the model\n",
    "\n",
    "When a PyTorch model is constructed in SageMaker, an entry point must be specified. This is the Python file which will be executed when the model is trained. Inside of the `train` directory is a file called `train.py` which has been provided and which contains most of the necessary code to train our model. The only thing that is missing is the implementation of the `train()` method which you wrote earlier in this notebook.\n",
    "\n",
    "**TODO**: Copy the `train()` method written above and paste it into the `train/train.py` file where required.\n",
    "\n",
    "The way that SageMaker passes hyperparameters to the training script is by way of arguments. These arguments can then be parsed and used in the training script. To see how this is done take a look at the provided `train/train.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"train\",\n",
    "                    role=role,\n",
    "                    framework_version='0.4.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 20,\n",
    "                        'hidden_dim': 300,\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-05 07:29:59 Starting - Starting the training job...\n",
      "2019-11-05 07:30:21 Starting - Launching requested ML instances......\n",
      "2019-11-05 07:31:25 Starting - Preparing the instances for training.........\n",
      "2019-11-05 07:32:31 Downloading - Downloading input data...\n",
      "2019-11-05 07:33:04 Training - Downloading the training image..\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-11-05 07:33:38,912 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-11-05 07:33:38,938 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-11-05 07:33:41,964 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-11-05 07:33:42,209 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-11-05 07:33:42,209 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-11-05 07:33:42,210 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-11-05 07:33:42,210 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[31mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/f8/82a8a6ed446b58aa718b2744b265983783a2c84098a73db6d0b78a573e25/numpy-1.17.3-cp35-cp35m-manylinux1_x86_64.whl (19.8MB)\u001b[0m\n",
      "\u001b[31mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\u001b[0m\n",
      "\u001b[31mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/c8/a55eb6ea11cd7e5ac4bacdf92bac4693b90d3ba79268be16527555e186f0/beautifulsoup4-4.8.1-py3-none-any.whl (101kB)\u001b[0m\n",
      "\u001b[31mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/62/bbd2be0e7943ec8504b517e62bab011b4946e1258842bc159e5dfde15b96/html5lib-1.0.1-py2.py3-none-any.whl (117kB)\u001b[0m\n",
      "\u001b[31mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (1.11.0)\u001b[0m\n",
      "\u001b[31mCollecting soupsieve>=1.2 (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/81/94/03c0f04471fc245d08d0a99f7946ac228ca98da4fa75796c507f61e688c2/soupsieve-1.9.5-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: nltk, train\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\n",
      "2019-11-05 07:33:38 Training - Training image download completed. Training in progress.\u001b[31m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bmvel_kw/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built nltk train\u001b[0m\n",
      "\u001b[31mInstalling collected packages: pytz, numpy, pandas, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[31mSuccessfully installed beautifulsoup4-4.8.1 html5lib-1.0.1 nltk-3.4.5 numpy-1.17.3 pandas-0.24.2 pytz-2019.3 soupsieve-1.9.5 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.3.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-11-05 07:33:54,238 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-11-05-07-29-58-619\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"log_level\": 20,\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"hidden_dim\": 300\n",
      "    },\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-227365329998/sagemaker-pytorch-2019-11-05-07-29-58-619/source/sourcedir.tar.gz\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"additional_framework_parameters\": {}\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"20\",\"--hidden_dim\",\"300\"]\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":20,\"hidden_dim\":300}\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-west-2-227365329998/sagemaker-pytorch-2019-11-05-07-29-58-619/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_HP_HIDDEN_DIM=300\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"hidden_dim\":300},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2019-11-05-07-29-58-619\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-227365329998/sagemaker-pytorch-2019-11-05-07-29-58-619/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --epochs 20 --hidden_dim 300\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mUsing device cuda.\u001b[0m\n",
      "\u001b[31mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mModel loaded with embedding_dim 32, hidden_dim 300, vocab_size 5000.\u001b[0m\n",
      "\u001b[31mEpoch: 1, BCELoss: 0.6722895065132453\u001b[0m\n",
      "\u001b[31mEpoch: 2, BCELoss: 0.6485142452376229\u001b[0m\n",
      "\u001b[31mEpoch: 3, BCELoss: 0.5896030761757676\u001b[0m\n",
      "\u001b[31mEpoch: 4, BCELoss: 0.4859071969985962\u001b[0m\n",
      "\u001b[31mEpoch: 5, BCELoss: 0.41466698415425357\u001b[0m\n",
      "\u001b[31mEpoch: 6, BCELoss: 0.3901210658404292\u001b[0m\n",
      "\u001b[31mEpoch: 7, BCELoss: 0.3548313640818304\u001b[0m\n",
      "\u001b[31mEpoch: 8, BCELoss: 0.31649115681648254\u001b[0m\n",
      "\u001b[31mEpoch: 9, BCELoss: 0.30279055268180616\u001b[0m\n",
      "\u001b[31mEpoch: 10, BCELoss: 0.29872612715983876\u001b[0m\n",
      "\u001b[31mEpoch: 11, BCELoss: 0.2695513395022373\u001b[0m\n",
      "\u001b[31mEpoch: 12, BCELoss: 0.2614879100298395\u001b[0m\n",
      "\u001b[31mEpoch: 13, BCELoss: 0.2529852861652569\u001b[0m\n",
      "\u001b[31mEpoch: 14, BCELoss: 0.238973966362525\u001b[0m\n",
      "\u001b[31mEpoch: 15, BCELoss: 0.23300966346750454\u001b[0m\n",
      "\u001b[31mEpoch: 16, BCELoss: 0.22982606170128803\u001b[0m\n",
      "\u001b[31mEpoch: 17, BCELoss: 0.22317814066702005\u001b[0m\n",
      "\u001b[31mEpoch: 18, BCELoss: 0.2072664560103903\u001b[0m\n",
      "\u001b[31mEpoch: 19, BCELoss: 0.19403298959440116\u001b[0m\n",
      "\u001b[31mEpoch: 20, BCELoss: 0.16730098928115805\u001b[0m\n",
      "\u001b[31m2019-11-05 07:42:50,698 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-11-05 07:43:49 Uploading - Uploading generated training model\n",
      "2019-11-05 07:43:49 Completed - Training job completed\n",
      "Training seconds: 678\n",
      "Billable seconds: 678\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Testing the model\n",
    "\n",
    "As mentioned at the top of this notebook, we will be testing this model by first deploying it and then sending the testing data to the deployed endpoint. We will do this so that we can make sure that the deployed model is working correctly.\n",
    "\n",
    "## Step 6: Deploy the model for testing\n",
    "\n",
    "Now that we have trained our model, we would like to test it to see how it performs. Currently our model takes input of the form `review_length, review[500]` where `review[500]` is a sequence of `500` integers which describe the words present in the review, encoded using `word_dict`. Fortunately for us, SageMaker provides built-in inference code for models with simple inputs such as this.\n",
    "\n",
    "There is one thing that we need to provide, however, and that is a function which loads the saved model. This function must be called `model_fn()` and takes as its only parameter a path to the directory where the model artifacts are stored. This function must also be present in the python file which we specified as the entry point. In our case the model loading function has been provided and so no changes need to be made.\n",
    "\n",
    "**NOTE**: When the built-in inference code is run it must import the `model_fn()` method from the `train.py` file. This is why the training code is wrapped in a main guard ( ie, `if __name__ == '__main__':` )\n",
    "\n",
    "Since we don't need to change anything in the code that was uploaded during training, we can simply deploy the current model as-is.\n",
    "\n",
    "**NOTE:** When deploying a model you are asking SageMaker to launch an compute instance that will wait for data to be sent to it. As a result, this compute instance will continue to run until *you* shut it down. This is important to know since the cost of a deployed endpoint depends on how long it has been running for.\n",
    "\n",
    "In other words **If you are no longer using a deployed endpoint, shut it down!**\n",
    "\n",
    "**TODO:** Deploy the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-pytorch-2019-11-05-07-29-58-619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# TODO: Deploy the trained model\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Use the model for testing\n",
    "\n",
    "Once deployed, we can read in the test data and send it off to our deployed model to get some results. Once we collect all of the results we can determine how accurate our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pd.concat([pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into chunks and send each chunk seperately, accumulating the results.\n",
    "\n",
    "def predict(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = np.array([])\n",
    "    for array in split_array:\n",
    "        predictions = np.append(predictions, predictor.predict(array))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(test_X.values)\n",
    "predictions = [round(num) for num in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85212"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does this model compare to the XGBoost model you created earlier? Why might these two models perform differently on this dataset? Which do *you* think is better for sentiment analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "The accuracy score of this model is actually very close with XGBoost model I created earlier, which also had 0.85 score. However, there an LSTM model is aware of the order of words, meanwhile, a decision tree based model can only make sense of word occurences.\n",
    "\n",
    "With no evidence, I think that an LSTM model might perform better for sentiment analysis, or speech/text analysis in general, because this type of analysis benefits from a model which can understand the order of words, rather than just how many times a certain word appear in the data. An example of this is if a sentence has the phrase \"do not hate\", an LSTM might be able to understand that this is a positive phrase, when XGBoost might think it is negative because it contains \"not\" and \"hate\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) More testing\n",
    "\n",
    "We now have a trained model which has been deployed and which we can send processed reviews to and which returns the predicted sentiment. However, ultimately we would like to be able to send our model an unprocessed review. That is, we would like to send the review itself as a string. For example, suppose we wish to send the following review to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = 'The simplest pleasures in life are the best, and this film is one of them. Combining a rather basic storyline of love and adventure this movie transcends the usual weekend fair with wit and unmitigated charm.'\n",
    "#test_review = 'bad very bad and worst'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question we now need to answer is, how do we send this review to our model?\n",
    "\n",
    "Recall in the first section of this notebook we did a bunch of data processing to the IMDb dataset. In particular, we did two specific things to the provided reviews.\n",
    " - Removed any html tags and stemmed the input\n",
    " - Encoded the review as a sequence of integers using `word_dict`\n",
    " \n",
    "In order process the review we will need to repeat these two steps.\n",
    "\n",
    "**TODO**: Using the `review_to_words` and `convert_and_pad` methods from section one, convert `test_review` into a numpy array `test_data` suitable to send to our model. Remember that our model expects input of the form `review_length, review[500]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simplest', 'pleasur', 'life', 'best', 'film', 'one', 'combin', 'rather', 'basic', 'storylin', 'love', 'adventur', 'movi', 'transcend', 'usual', 'weekend', 'fair', 'wit', 'unmitig', 'charm']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = review_to_words(test_review)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert test_review into a form usable by the model and save the results in test_data\n",
    "test_data, length = convert_and_pad(word_dict, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data = np.array([length] + test_data).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have processed the review, we can send the resulting array to our model to predict the sentiment of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.9783044, dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(stacked_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the return value of our model is close to `1`, we can be certain that the review we submitted is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the endpoint\n",
    "\n",
    "Of course, just like in the XGBoost notebook, once we've deployed an endpoint it continues to run until we tell it to shut down. Since we are done using our endpoint for now, we can delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 (again) - Deploy the model for the web app\n",
    "\n",
    "Now that we know that our model is working, it's time to create some custom inference code so that we can send the model a review which has not been processed and have it determine the sentiment of the review.\n",
    "\n",
    "As we saw above, by default the estimator which we created, when deployed, will use the entry script and directory which we provided when creating the model. However, since we now wish to accept a string as input and our model expects a processed review, we need to write some custom inference code.\n",
    "\n",
    "We will store the code that we write in the `serve` directory. Provided in this directory is the `model.py` file that we used to construct our model, a `utils.py` file which contains the `review_to_words` and `convert_and_pad` pre-processing functions which we used during the initial data processing, and `predict.py`, the file which will contain our custom inference code. Note also that `requirements.txt` is present which will tell SageMaker what Python libraries are required by our custom inference code.\n",
    "\n",
    "When deploying a PyTorch model in SageMaker, you are expected to provide four functions which the SageMaker inference container will use.\n",
    " - `model_fn`: This function is the same function that we used in the training script and it tells SageMaker how to load our model.\n",
    " - `input_fn`: This function receives the raw serialized input that has been sent to the model's endpoint and its job is to de-serialize and make the input available for the inference code.\n",
    " - `output_fn`: This function takes the output of the inference code and its job is to serialize this output and return it to the caller of the model's endpoint.\n",
    " - `predict_fn`: The heart of the inference script, this is where the actual prediction is done and is the function which you will need to complete.\n",
    "\n",
    "For the simple website that we are constructing during this project, the `input_fn` and `output_fn` methods are relatively straightforward. We only require being able to accept a string as input and we expect to return a single value as output. You might imagine though that in a more complex application the input or output may be image data or some other binary data which would require some effort to serialize.\n",
    "\n",
    "### (TODO) Writing inference code\n",
    "\n",
    "Before writing our custom inference code, we will begin by taking a look at the code which has been provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_containers\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.optim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.utils.data\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LSTMClassifier\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m review_to_words, convert_and_pad\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[33m\"\"\"Load the PyTorch model from the `model_dir` directory.\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# First, load the parameters used to create the model.\u001b[39;49;00m\r\n",
      "    model_info = {}\r\n",
      "    model_info_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model_info = torch.load(f)\r\n",
      "\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_info: {}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model_info))\r\n",
      "\r\n",
      "    \u001b[37m# Determine the device and construct the model.\u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    model = LSTMClassifier(model_info[\u001b[33m'\u001b[39;49;00m\u001b[33membedding_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mvocab_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    \u001b[37m# Load the store model parameters.\u001b[39;49;00m\r\n",
      "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model.load_state_dict(torch.load(f))\r\n",
      "\r\n",
      "    \u001b[37m# Load the saved word_dict.\u001b[39;49;00m\r\n",
      "    word_dict_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mword_dict.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(word_dict_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model.word_dict = pickle.load(f)\r\n",
      "\r\n",
      "    model.to(device).eval()\r\n",
      "\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(serialized_input_data, content_type):\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mDeserializing the input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mtext/plain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "        data = serialized_input_data.decode(\u001b[33m'\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m data\r\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in content_type: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + content_type)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction_output, accept):\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mSerializing the generated output.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[36mstr\u001b[39;49;00m(prediction_output)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mInferring sentiment of input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[34mif\u001b[39;49;00m model.word_dict \u001b[35mis\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m:\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mModel has not been loaded properly, no word_dict.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# TODO: Process input_data so that it is ready to be sent to our model.\u001b[39;49;00m\r\n",
      "    \u001b[37m#       You should produce two variables:\u001b[39;49;00m\r\n",
      "    \u001b[37m#         data_X   - A sequence of length 500 which represents the converted review\u001b[39;49;00m\r\n",
      "    \u001b[37m#         data_len - The length of the review\u001b[39;49;00m\r\n",
      "\r\n",
      "    words = review_to_words(input_data)\r\n",
      "    data_X, data_len = convert_and_pad(model.word_dict, words)\r\n",
      "\r\n",
      "    \u001b[37m# Using data_X and data_len we construct an appropriate input tensor. Remember\u001b[39;49;00m\r\n",
      "    \u001b[37m# that our model expects input data of the form 'len, review[500]'.\u001b[39;49;00m\r\n",
      "    data_pack = np.array([data_len] + data_X)\r\n",
      "    data_pack = data_pack.reshape(\u001b[34m1\u001b[39;49;00m, -\u001b[34m1\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    data = torch.from_numpy(data_pack)\r\n",
      "    data = data.to(device)\r\n",
      "\r\n",
      "    \u001b[37m# Make sure to put the model into evaluation mode\u001b[39;49;00m\r\n",
      "    model.eval()\r\n",
      "\r\n",
      "    \u001b[37m# TODO: Compute the result of applying the model to the input data. The variable `result` should\u001b[39;49;00m\r\n",
      "    \u001b[37m#       be a numpy array which contains a single integer which is either 1 or 0\u001b[39;49;00m\r\n",
      "    y = model(data)\r\n",
      "    result = y.detach().numpy().round().astype(np.int64)\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m result\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize serve/predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the `model_fn` method is the same as the one provided in the training code and the `input_fn` and `output_fn` methods are very simple and your task will be to complete the `predict_fn` method. Make sure that you save the completed file as `predict.py` in the `serve` directory.\n",
    "\n",
    "**TODO**: Complete the `predict_fn()` method in the `serve/predict.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the model\n",
    "\n",
    "Now that the custom inference code has been written, we will create and deploy our model. To begin with, we need to construct a new PyTorchModel object which points to the model artifacts created during training and also points to the inference code that we wish to use. Then we can call the deploy method to launch the deployment container.\n",
    "\n",
    "**NOTE**: The default behaviour for a deployed PyTorch model is to assume that any input passed to the predictor is a `numpy` array. In our case we want to send a string so we need to construct a simple wrapper around the `RealTimePredictor` class to accomodate simple strings. In a more complicated situation you may want to provide a serialization object, for example if you wanted to sent image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import RealTimePredictor\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "class StringPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(StringPredictor, self).__init__(endpoint_name, sagemaker_session, content_type='text/plain')\n",
    "\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='0.4.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='serve',\n",
    "                     predictor_cls=StringPredictor)\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "\n",
    "Now that we have deployed our model with the custom inference code, we should test to see if everything is working. Here we test our model by loading the first `250` positive and negative reviews and send them to the endpoint, then collect the results. The reason for only sending some of the data is that the amount of time it takes for our model to process the input and then perform inference is quite long and so testing the entire data set would be prohibitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def test_reviews(data_dir='../data/aclImdb', stop=250):\n",
    "    \n",
    "    results = []\n",
    "    ground = []\n",
    "    \n",
    "    # We make sure to test both positive and negative reviews    \n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        \n",
    "        path = os.path.join(data_dir, 'test', sentiment, '*.txt')\n",
    "        files = glob.glob(path)\n",
    "        \n",
    "        files_read = 0\n",
    "        \n",
    "        print('Starting ', sentiment, ' files')\n",
    "        \n",
    "        # Iterate through the files and send them to the predictor\n",
    "        for f in files:\n",
    "            with open(f) as review:\n",
    "                # First, we store the ground truth (was the review positive or negative)\n",
    "                if sentiment == 'pos':\n",
    "                    ground.append(1)\n",
    "                else:\n",
    "                    ground.append(0)\n",
    "                # Read in the review and convert to 'utf-8' for transmission via HTTP\n",
    "                content = review.read()\n",
    "                print(content[:100] + '...')\n",
    "                review_input = content.encode('utf-8')\n",
    "                # Send the review to the predictor and store the results\n",
    "                y = predictor.predict(review_input)\n",
    "                results.append(int(y))\n",
    "                \n",
    "            # Sending reviews to our endpoint one at a time takes a while so we\n",
    "            # only send a small number of reviews\n",
    "            files_read += 1\n",
    "            if files_read == stop:\n",
    "                break\n",
    "                \n",
    "    return ground, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting  pos  files\n",
      "James Cagney, racketeer and political ward heeler, get to become a Deputy Commissioner of Correction...\n",
      "I bought this a while back, during a massive martial arts movie phase. Although this certainly ain't...\n",
      "The story told by The Cranes are Flying is not, admittedly, all that original. Young lovers are sepa...\n",
      "Spin-offs, for somebody who don't know, are not usually successful because most of the original char...\n",
      "The answer.....No, sadly not. Though miller and the sweep has to be hailed as a most whimsical cinem...\n",
      "Have just seen the last episode, No 32, (though the site says only 30 episodes were made) and I must...\n",
      "for many and many years, gaijin have visited japan for learning martial arts, instead of acquiring a...\n",
      "\"National Velvet\" tells the story of Velvet Brown, a young English girl with dreams of entering her ...\n",
      "i really liked this film.it features John Wayne in his first starring performance.even then,you can ...\n",
      "I`ve seen this movie twice, both times on Cinemax. The first time in it`s unrated version which is s...\n",
      "This movie doesn't have any pretense at being great art, which is good. But it is a well written scr...\n",
      "AWWWW, I just love this movie to bits. Me and my cousins enjoy this movie a lot and I am just such a...\n",
      "Obviously made on the cheap to capitalize on the notorious \"Mandingo,\" this crassly pandering hunk o...\n",
      "Radio is a true story about a man who did what he felt, in his heart, was the right thing to do. The...\n",
      "SPOILERS AHEAD------------------------- Mel has got it going on. From the opening credits to the end...\n",
      "Wow, I just LOVED watching all these hot babes! The scenery around Malibu and California was off the...\n",
      "Big fat liar is a pretty funny movie. But as I was watching it, I thought about something. Some of t...\n",
      "Ettore Scola's masterful rendering of this epic of the heart deserves a much wider audience. It is a...\n",
      "All of the trials and tribulations of making a no budget movie right from the mouths of those involv...\n",
      "I have just watched the season 2 finale of Doctor Who, and apart from a couple of dull episodes this...\n",
      "Footprints certainly isn't your average run of the mill Giallo, and that's no bad thing. Unlike his ...\n",
      "They don't make movies like this anymore  though some may say that's a good thing. Although this wa...\n",
      "Frank Langella steals my heart in everything he has ever been in! I love watching him!! i was 10 yrs...\n",
      "I saw \"Into Pitch Black\" on t.v. and so I had to see this. I must say, I was very impressed.<br /><b...\n",
      "This short was nominated for an Academy Award, losing to Anna and Bella. Not since Doctor Strangelov...\n",
      "So many great talents were utilized in \"The Best Years of Out Lives\", the result has to be somewhat ...\n",
      "Being 15 myself I enjoyed this flick thouroughly!! I related to the character Ann August more than m...\n",
      "One night, barkeeper Randy (Matt Dillon) rescues Jewel (Liv Tyler) from her jealous boyfriend Utah (...\n",
      "The Youth In Us is a pitch-perfect gem. I saw this stunning short at this year's 2005 Sundance Festi...\n",
      "A wonderful family movie & a beautiful horse movie. 75+ %entertainment. Casey, Buddy, Kelly Marsh ar...\n",
      "Hey, its great not to have to wait for the next Star-Trek convention to see hick-trek! Its a cheesy ...\n",
      "Beautiful art direction, excellent editing and wonderful stories make this some of the best televisi...\n",
      "A very interesting plot of the film based on the novel \"Waltz into Darkness\" of the writer Cornell W...\n",
      "The first time you watch this movie you may hate it, but the 2nd time you see this movie I guarantee...\n",
      "This movie dethroned Dr. Giggles as the best horror movie I've ever seen. The plot was great, the pl...\n",
      "The movie has taken a little flack for playing fast and loose with the facts. But it will put you cl...\n",
      "Tracy and Matt, Michelle and Sebastian: these are the two couples whose lives of addiction, crime, a...\n",
      "having never actually seen anything by this beloved of the luvvies, let alone a production of mercha...\n",
      "The very first time I heard of Latter Days was when I was renting DVD's and I was interested as I am...\n",
      "The movie is based on a Jules Verne book I actually have read once, about ten years ago. I remember ...\n",
      "A real sudsy soap opera here as Spencer Tracy tackles the role of an illiterate until the age of 20....\n",
      "I was very impressed with with this film which was directed by (Luigi Bazzoni). The story was about ...\n",
      "Although Bullet In The Brain is, without question, superior amongst short films, it largely seems mo...\n",
      "The above profile was written by me when I used the nick of OldWereWolf56 which is still my email ad...\n",
      "I liked this movie. Many people refer to it as \"Sabrina the Teenage Feminist\". They do that with a l...\n",
      "This film has a decidedly weird setting, taking place in a school that's really old to begin with bu...\n",
      "If you have not seen this late 80s film about the the Washington Bureau of a Network News station th...\n",
      "A young woman leaves her provincial life for a new one in the city and there she meets another woman...\n",
      "I have seen and enjoyed all of the Chameleon movies and I must say they keep getting better & better...\n",
      "This was essentially a remake of \"Diagnosis Murder\" minus Victoria Rowell, Scott Baio & Charlie Schl...\n",
      "I think that just sums up this film. Watch it and you'll find out why. The acting of the lead charac...\n",
      "Well, this is new...Famous Italian horror director Lucio Fulci shoots a film about a famous Italian ...\n",
      "Miyazaki's Studio Ghibli shows his wonderful touch animating, infusing life, in every little action ...\n",
      "I have read reviews of this film that found it 'disappointing' and 'confused'. I am at a loss to und...\n",
      "i think this show is awesome!!! i love it, and i love Fabian (not in a romantic kind of way) but if ...\n",
      "I just saw this movie tonight(5th Nov. 2005)for the first time. I wanted to watch it cause I saw the...\n",
      "Look, we rated this a 10 on entertainment value. It's a comedy sure, not an epic like Lord of the Ri...\n",
      "This review contains what might be a spoiler if you never read the book or saw the cover of the vide...\n",
      "The most amazing film I have ever seen. I didn't read the programming and I just stumbled onto the m...\n",
      "Previous reviewer Claudio Carvalho gave a much better recap of the film's plot details than I could....\n",
      "Subject Matter: Cosmology, Quantum Physics and Stephen Hawking<br /><br />Soundtrack: Phillip Glass<...\n",
      "I admire Deepa Mehta and this movie is a masterpiece. I'd recommend to buy this movie on DVD because...\n",
      "I'm torn about this show. While MOST parts of it I found to be HILARIOUS, other parts of it I found ...\n",
      "Has the proliferation of relatively high quality shows on the proliferating TV networks made it poss...\n",
      "I finally managed to see this movie...after so many years of expectancy...<br /><br />I was so curio...\n",
      "This was recommended to me by a friend that said it was cute and cuddly for a \"lesbian sexuality Fli...\n",
      "I tend to get furious when hearing about Lucio Fulci's reputation as a director. Too often he's cate...\n",
      "B.B. Thornton proves to be a great actor in this little seen movie. Thornton really gets into his ch...\n",
      "I LOVE THIS MOVIE!!!<br /><br />This beautiful, charming love story drew me in immediately with its ...\n",
      "typically, a movie can have factors like \"arousing\", \"good feel\", \"sense of purpose\", \"plot\", etc. T...\n",
      "When this movie firt came out in 1995, I found it amazingly great. Especially with Sandra Bullock.Af...\n",
      "TV churns out dozens of true-crime movies every year. You can see 3 or 4 every Saturday on Lifetime,...\n",
      "what a refreshing change from the PG movies that have teen girls jumping in and out of bed, young hi...\n",
      "Venice, in 1596.Jews are separated from the good Christians.Bassanio, a young but poor Venetian love...\n",
      "Starting with a \"My Name is Joe\" like scene in Alcoholics Anonymous tBM careers into a mad spiral of...\n",
      "A couple of years before SCREAM spoofed the slasher/horror genre with savvy, self-conscious young th...\n",
      "On account of my unfortunately not being able to find them anywhere, I have not gotten to try any of...\n",
      "First off I want to say most of the people who give this a poor review don't like this kind of comed...\n",
      "There are a few aspects to Park's movies, and in particular Wallace & Gromit, that I would say make ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An absolute classic of 80's scare flix. This one isn't like any other as it pits pint-size, wild-eye...\n",
      "Martino, a young teacher in the island of Elba, has been formed by Maestro Fontanelli, an excellent ...\n",
      "Spirit and Chaos is an artistic biopic of Miyazawa Kenji, a Japanese poet and writer who was active ...\n",
      "This BBC series is astonishingly good fun. I'd only seen a few minutes before I knew I had to own it...\n",
      "This is my favorite movie that portrays African Americans in whole different light. because it shows...\n",
      "The Merchant of Venice 8/10<br /><br />(This review assumes a basic knowledge of the story and so ma...\n",
      "What is there to say about an anti-establishment film that was produced in a time of such colourless...\n",
      "Set in 1962 Hong Kong (in turbulent times, as we are informed), this extremely intimate story of a f...\n",
      "This is a true gem of a TV film. Based on a completely untrue story, it follows the course of the do...\n",
      "This is a film about loneliness and how the distance  physical and emotional -- between people tend...\n",
      "\"... the beat is too strong ... we're deaf mutants now--like them\", Rex Voorhas Ormine<br /><br />I ...\n",
      "Enchanting. The best time to see this movie is sometime when unhappy or sad. It's all just so cute, ...\n",
      "The film had NO help at all, promotion-wise: if there was an advertising promo on TV or radio, I did...\n",
      "Leland P. Fitzgerald (Ryan Gosling) has committed an unspeakable crime, the stabbing of the retarded...\n",
      "\"The Long Kiss Goodnight\" is an enjoyable and very cool action thriller, and a career breakthrough f...\n",
      "First half of the movie scared the hell out of me and normally I'm not easy to scare, but second hal...\n",
      "The subject matter of this film is potentially depressing: a man about thirty, with no job, little e...\n",
      "I ended up liking this movie but it was not the easiest to get through. What makes the movie great i...\n",
      "Just finished this impressively nutty affair and whilst I can't say as it was as good as I had hyped...\n",
      "It is a wonderful film about people. Strange people. The characters in the movie all have a very tra...\n",
      "\"Stripperella\" is an animated series about a girl named Erotica Jones (voiced by Pamela Anderson) wh...\n",
      "So many of us who are devoted to the \"art\" of the motion picture will disregard or forget that movie...\n",
      "Mike Nichols' film \"Charlie Wilson's War\", set in the 1980's, tells the story of how the title chara...\n",
      "Many consider BEAST STABLE to be the last of the \"true\" FEMALE PRISONER films, as it is the last of ...\n",
      "I thought this movie was brilliant. It was so funny and so true too. A great idea for a movie. Five ...\n",
      "To think this film was made the year I was born. To think people are still having their constitution...\n",
      "This movie was beautiful and touching. It touched a place deep inside me and I'm not sure why. I am ...\n",
      "Years ago I read the book 'A Máquina' (The machine). As I re-read this little book again and again, ...\n",
      "How do these guys keep going? They're about 50 years old each, and act as if they're only 30. They p...\n",
      "This is a fun movie with subtle intention. Its off-beat comedy is hilarious to me, unfunny to my fri...\n",
      "Can't say this wasn't made well. At a recent film festival the director admitted some scenes took 30...\n",
      "Very literate, intelligent drama about a group of international travelers held virtual prisoners in ...\n",
      "I feel very strongly that this film was just like Waiting to Exhale with white females in the 1950's...\n",
      "***SPOILERS*** ***SPOILERS*** I loved the set-up and consistently laughed throughout the entire movi...\n",
      "My sister, dad, and I are really into D&D and one night we were browsing Netflix looking for a movie...\n",
      "I haven't read the Anne Rice novel that this movie was based on, but who knows, maybe reading the bo...\n",
      "Clearly patterned after the first gangster movies that Warner produced the same year,Little Caesar (...\n",
      "I have recently watched this film, and have decided to comment on it. <br /><br />the best way to wa...\n",
      "When I was growing up, Voyage into Space was my most favorite movie. I remember the time when KTLA (...\n",
      "Shadows breathes the smell of New York's streets like no film before it. This kick off of Cassavetes...\n",
      "The Lubitsch's Touch is more than ever in this film. Humour at anytime and very subtle. The plot is ...\n",
      "Snakes on a Plane was such a well hyped film that it was both inevitable and a little crazy to try t...\n",
      "Being a middle aged mom myself, I very much appreciated seeing a romance between grown-up people tha...\n",
      "Well, okay, maybe not perfect, but it was pretty close. This movie jumped from crime drama to romant...\n",
      "I don't normally go out of my way to watch romantic comedy, and maybe I will in the future after see...\n",
      "This movie is a classic. Kids now will love it, and people like me, who were kids when it first came...\n",
      "Loved the shots of airports -- Dallas, Phoenix, Fresno, etc., just single buildings with the name in...\n",
      "Comic secret agents have made a comeback in recent years, with Mike Myers' 'Austin Powers' and Rowan...\n",
      "Buddy Holly was a pioneer and victim of the early days of rock 'n' roll. The young singer/songwriter...\n",
      "Black Scorpion is a fun flick about a groovy female super heroine who wears leather tights and drive...\n",
      "This film gave me probably the most pleasant surprise of any I've ever seen. It was not a big-budget...\n",
      "Basically an endearingly chintzy and moronic $1.50 version of the nifty early 80's subterranean crea...\n",
      "Who said it had to be believable? Do yourself a favor and turn off your ration before you sit down t...\n",
      "In all truth, this really isn't a \"movie\" so much as an extended final episode; by this I mean that,...\n",
      "Never posted anything here before, but after watching Noroi I just felt that I had to write down my ...\n",
      "A brilliant Sherlock Holmes adventure starring the brilliant Basil Rathbone and Nigel Bruce. Despite...\n",
      "For once a story of hope highlighted over the tragic reality our youth face. Favela Rising draws one...\n",
      "I Feel the Niiiiiight Heat! I feel your HEEAAAAAAAAAART-beat! Something ain't right!\" Theme song wri...\n",
      "I especially liked the ending of this movie--I really felt what the characters must have felt, which...\n",
      "Sarah Plain and Tall's Winters end was the best movie I have ever seen. The person in the story that...\n",
      "This film grabbed me right from its start, where a sweet-looking teen-aged girl is shown visiting a ...\n",
      "This is the final episode we deserved. At the end of the last season, things were left in a 'life go...\n",
      "My impression, having seen this documentary, is that Nathaniel Kahn ended up with more questions tha...\n",
      "Don't ask me why I love this movie so much...Maybe it came at a time in my life I desperately wanted...\n",
      "Gamers: DR is not a fancy made movie, it's more like amateur video. Horrible magic effect, really fa...\n",
      "This is a great show despite many negative user reviews. The aim of this show is to entertain you by...\n",
      "There are a lot of people that put down on these type 80's movies but those people may not have been...\n",
      "How important is the director, anyway? In this film, made in the politically tumultuous times of the...\n",
      "The three-part series ended last night on PBS, which I believe was its first wide exposure to an Ame...\n",
      "This short subject gathered kudos from all kinds of places for its plea for religious toleration. <b...\n",
      "With the fairly recent release of Carlos Saura's 'Fados' in the United States (albiet a limited art ...\n",
      "Wow! My mom bought me this movie because it was on sale really cheap in some store in my town, and s...\n",
      "I was so moved by this film in 1981, I went back to the theater four times to see it again! Somethin...\n",
      "I have always been fascinated by silent films. There is something about seeing actors and actresses ...\n",
      "I just saw this film again, I believe for the sixth time. I will doubtless see it many more times. T...\n",
      "In the late eighties and early nineties the decline and death of independent video companies like Ve...\n",
      "It may be a little creaky now, and it certainly can never have the impact it once had, but this is s...\n",
      "This movie I watched back in 1981 when it came out. Although I missed the first part of the movie wh...\n",
      "The Andrew Davies adaptation of the Sarah Waters' novel was excellent. The characters of Nan and and...\n",
      "I have seen this film probably a dozen times since it was originally released theatrically. Anyone w...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This has to be my favourite film. The script is sharp and played to the limit by an excellent Miller...\n",
      "The magnificent Greta Garbo is in top form in this, her first talkie. She gets fine support from the...\n",
      "Think of it as an extreme form of detention without trial. Without commenting and taking a side on t...\n",
      "Watched this flick on Saturday afternoon cable. Man, did it drag. I got the metaphors, symbolism, an...\n",
      "This movie was amazing. Never before have I seen such a film that brought me to the harsh reality of...\n",
      "The history of TV to film adaptations are littered with aberrations which almost conclusively prove ...\n",
      "The marriage of an upscale New York City couple with child falls apart when the wife wants out (\"It ...\n",
      "Leos Carax has made 3 great movies: Boys Meet Girls, Mauvais Sang, Les Amants du Pont Neuf. In fact ...\n",
      "Cam Archer's lyrical Bobbycrush boldly captures the disorienting kaleidoscope that is adolescent des...\n",
      "This is a wonderful film taking place during the romantic period of the Civil War. This film is a mu...\n",
      "Back when I was working person, I remember having a really obnoxious client to deal with who insiste...\n",
      "i love this movie. it focuses on both issues: reality and fantasy. reality because hey, we all wante...\n",
      "Watching this PPV, I had high expectations for it, since Smackdown is the best show in WWE, this is ...\n",
      "This film is probably Hal Hartley's best one. The subject, of a unusual originality, is treated (tha...\n",
      "As a teenager, I watched this movie every time it was on TV (and it was on a LOT) because of its wit...\n",
      "Accepted...let's see. The only reason why i had chosen to see that movie was the hot dog shown in co...\n",
      "L'Homme Blesse is not for an impatient, adventure-seeking audience. There are no explosions nor is t...\n",
      "I've seen both movies and I saw without a doubt the re-make is the best, I know a lot of people woul...\n",
      "At first I couldn't tell if it was an art film or a documentary. The day after I had a unique movie ...\n",
      "When I saw Gone with the wind I thought that there could not be better actors than Vivian Leigh and ...\n",
      "While escaping from a heist of a bank, the outlaw Vance Shaw (Randolph Scott) helps Edward Creighton...\n",
      "To this day, there isn't a movie I've seen more times than The Chipmunk Adventure, nor has any movie...\n",
      "\"House Calls\" is a wonderful romantic comedy that can best be described as \"how they used to make th...\n",
      "If you like movies that will make you think, this is absolutely one of the good ones. I always liked...\n",
      "...this film noire set piece suffers from murky sound (at least, as shown on the inadequate equipmen...\n",
      "I've seen 'nurse betty' twice in september 2000 on the international film festival 'films by the sea...\n",
      "\"Rififi\" is a terrific heist movie, and one from which subsequent heist films have drawn ever since....\n",
      "Beware, My Lovely is an experimental studio film from the early fifties and was directed by a man, H...\n",
      "I went to see Glenn McQuaid's \"I Sell The Dead\" in it's North American premiere at the Toronto After...\n",
      "It was easy to get lost in the simplicity and light hearted humor of this year's best family film......\n",
      "Someone reviewed this movie as a \"waste of time\" because he/she was expecting the \"beautiful scenery...\n",
      "2005 will go down in 'Dr.Who' history as its most incredible year. Everything seemed to click; a fir...\n",
      "This show is awesome! I love all the actors! It has great story lines and characters. It is the perf...\n",
      "This movie literally had me rolling on the floor (well at least on the couch) laughing. I didn't thi...\n",
      "This is one of the anime films from The Animatrix collection, one of nine - the only one done in bla...\n",
      "I'm impressed that 'Hail the Woman' was made at all; released just one year after American women got...\n",
      "In some scenes in the Rain People, Francis Ford Coppola's precursor to his hey-day of the seventies,...\n",
      "I saw Marigold at a preview showing a few days ago, and found it to be a thoroughly engrossing and e...\n",
      "In Truffaut book-length interview with Hitchcock, it's apparent that Big Al's fear from the police d...\n",
      "Most movies from Hollywood seem to follow one of a few pre-formulated and very predictable plots. Th...\n",
      "Man! I remember this show with nostalgic... I really dug Bravestarr because he wasn't the convention...\n",
      "What's there to say about \"Pink Flamingos\"? It is beyond criticism or even explanation because it do...\n",
      "This film would have put the typical Hollywood \"tearjerkers\" to shame. The emotions portrayed are su...\n",
      "Luis Bunuel has always been a filmmaker whose work was obscure to me. My first experience with him w...\n",
      "This is a great film with an amazing cast. Crispen Glover is at his freakiest . His guitar solo is a...\n",
      "i have to admit thanks to this movie i'm now afraid of mannequins. hahaha.<br /><br />but yes, first...\n",
      ".. is the Princess Bride meets... well Trainspotting. But wait, really, it's a good combination! Thi...\n",
      "Of course, how could he. He obviously co-opted several aspects from that excellent movie, which was ...\n",
      "Caroline Bender (Hope Lange) is just killing time getting a job. Her real ambition is to marry Eddie...\n",
      "Loved it! This has to be the best horror flick of the 90's. I<br /><br />was at the edge of my seat....\n",
      "I always wanted to see this film and when I finally got to I knew I was in for a nice surprise when ...\n",
      "I guess I do not have too much to add. I found the comedy to still be funny after more than ten year...\n",
      "True, this is not John Sayles finest film (Brother From Another Planet) but it is not entirely forge...\n",
      "The subject of this movie is disturbing. How could some otherwise intelligent, religious, hard-worki...\n",
      "What can I say about this band, I was hooked in 68, I was a ten year old kid, I grew up on the Blues...\n",
      "Saw this film during the Mod & Rockers fest in August. I was so inspired and touched. Harry had an a...\n",
      "Tom Fontana's unforgettable \"Oz\" is hands down one of the greatest television series ever created. B...\n",
      "This is the question that astronauts Roy Thinnes and Ian Hendry ask themselves when they discover a ...\n",
      "Based on actual events of 1905, silent film THE BATTLESHIP POTEMKIN concerns an Imperial Russian shi...\n",
      "After going to sleep out of sheer loneliness, Lestat wakes from a 100-year sleep to the sounds of a ...\n",
      "Before I talk about the ending of this film I will talk about the plot. Some dude named Gerald break...\n",
      "For the sake of propaganda during World War II, Sherlock Holmes was moved into the then-present. One...\n",
      "I honestly can't believe that this film isn't more highly rated. Claude Chabrol could be described a...\n",
      "Drawn by Pain is easily one of the best pieces of cinema I have ever seen. Here are my reviews of th...\n",
      "this movie is simply amazing.. unfortunately in Portugal not even a shadow of him... and i agree wit...\n",
      "This one of those social dramas that WB knew how to put together and were guaranteed boxoffice hits ...\n",
      "I watched this series after I had seen the Naked Gun films. I found it much better than the films, a...\n",
      "Hilarious, clean, light-hearted, and quote-worthy. What else can you ask for in a film? This is my a...\n",
      "The Diary of Anne Frank is the second best-selling nonfiction book in the world, and for good reason...\n",
      "Many people have the irritating habit of dying before completing a vital message, thus confusing the...\n",
      "**SPOILERS** Shocking yet true story of the horror that befell the Alabama/Georgia border town of Ph...\n",
      "I smiled through the whole film. The music is great. The story-telling is great. It's a wonderful fi...\n",
      "William Shakespeare's Merchant of Venice portrays 16th century Venice. Al Pacino plays Shylock, a Je...\n",
      "I watched this mini in the early eighties. Sam Waterson proved himself to be a great actor. In fact ...\n",
      "The Director loves the actress and it shows. The actress inhabits the character, whom we love at fir...\n",
      "The film begins with a cranky old Broadway producer (exceptionally well-played by veteran character ...\n",
      "And with those words one of the great movie publicity campaigns came to a conclusion. 'Garbo Talks' ...\n",
      "Wow. this movie is the voice of a climbing generation. Director Sam Keith takes us to the darkest de...\n",
      "A story about love and hate, tragedy and happiness, and most of all, friendship set in the very inte...\n",
      "One of the intriguing aspects of this historical drama is the way the \"Tories\" or British American L...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A boy who adores Maurice Richard of the Montreal Canadiens receives, much to his horror, a Toronto M...\n",
      "I just saw it at an advance screening I haven't read the book, but heard many good things about it.<...\n",
      "There are frames in this film that could be Renoir paintings with vivid colors against muted backgro...\n",
      "I thought this movie was fun. I have never really watched old movies before and this one was a reall...\n",
      "The worst movie ever?? HARDLY!!! This is one of the BEST animated movies i have ever seen! It has ap...\n",
      "Is torture ever right? No The answer is simple and absolute with no qualifications possible. The rea...\n",
      "While watching a mundane modern movie (The Runaway Bride) with my granddaughter (age 22) she asked m...\n",
      "Pola X is a beautiful adaption of Herman Melville's 'Pierre; or, the Ambiguities'. The comments on h...\n",
      "As a modern Marco Polo, from Venice to China, here we come Amelio, again, taking on the task to rend...\n",
      "This movie is just about as good as the first Jackass, but with slightly more disgusting skits. I wo...\n",
      "During the making of this movie I once caught a statement on television about it. Something like: \"I...\n",
      "Starting  neg  files\n",
      "Kathy Ireland: the body of a goddess, the face of an angel, the voice of a Smurf.<br /><br />And the...\n",
      "I really wanted to like this film for all sorts of reasons -- the subject matter is inherently inter...\n",
      "OK, this is one strange film! Fans of Ed Wood Jr. will appreciate the \"inventive\" techniques directo...\n",
      "Sorry for all you guys that are not family with the Lynches.<br /><br />My sister in law asked me ho...\n",
      "Even my five year old was bored.<br /><br />Very predictable, and overacted. This movie couldn't mak...\n",
      "Business Executive is kidnapped, made to wander miles and miles in a woodland for days and days exch...\n",
      "An interesting slasher film with multiple suspects.<br /><br />Includes typical girl flashing her br...\n",
      "A clever overall story/location for a story. Action is respectable. The children are annoying and th...\n",
      "While babysitting at an isolated Colorado house, a teen girl is terrorized by an elusive murderer on...\n",
      "Although this starts out promisingly, a woman in a car is weaving around dark roads in the middle of...\n",
      "Before I sat down and watched this film on HBO, I wasn't expecting nothing but a few laughs here and...\n",
      "I had never heard of this film until it came to DVD. I was immediately intrigued by everything about...\n",
      "I can't help thinking that this is Franco's 'hamage' to the Marquis de Sade's \"One Thousand Days of ...\n",
      "This was one of the most mixed up films I have ever seen. Everything in the movie seemed to be attac...\n",
      "A pre-Nerd Robert Carradine, a pre-Automan Desi Arnaz Jr., and an almost pre-pubescent Melanie Griff...\n",
      "Stars: Hayden Pantierre.<br /><br />There have been so many movies that have this exact same plot, a...\n",
      "Is it a poorly acted, cliche-ridden pile of trash? Of course. Anyone who doesn't realize that when t...\n",
      "I saw this on a cheap DVD release with the title \"The Entity Force\". Since I enjoy cheesy 80's horro...\n",
      "I've never seen the original movie others have commented on, so my perspective is just about this mo...\n",
      "Although i watched this film by myself(thankfully), i still felt embarrassed while watching it. I wa...\n",
      "Doesn't anyone bother to check where this kind of sludge comes from before blathering on about its s...\n",
      "Tim Taylor is an abusive acholoic drug addict. He's a coward and a child and has absolutely no redee...\n",
      "This TVM seems to have polarised opinions amongst the commentators on this page so perhaps I can set...\n",
      "When I was a younger(oh about 2)I watched Barney for the first time, and liked it. BUT, back then I ...\n",
      "Even die hard John Wayne fans will have to concede that this film is a mess. Wayne's character, John...\n",
      "I really wanted to love this movie, and not only cause it had Aaron Eckhart in it but I thought the ...\n",
      "This unintentionally amusing mid-80s TV movie is based on the premise that sex bomb Donna Mills (in ...\n",
      "After viewing \"Still Life\", a short film directed by Jon Knautz, I was genuinely excited for his fea...\n",
      "I'm glad I didn't pay to see 'The Wog Boy'.<br /><br />I sat there hopefully waiting for something o...\n",
      "May be spoilers so do not read if you do not want to Just like watching the TV news , everything is ...\n",
      "If you're looking for a movie that puts you to sleep, then Heart of Darkness is the movie for you. T...\n",
      "<br /><br />I tuned into this movie not because I am a fan of U.S. High School basketball (in fact I...\n",
      "<br /><br />Summary: Not worth the film<br /><br />As an avid Gone With the Wind fan, I was disappoi...\n",
      "This piece of crap doesn't worth a critical review so I'll write some information for those who don'...\n",
      "After watching Avalon (which was decent only because of the very nice digital fx), and several anime...\n",
      "simply i just watched this movie just because of Sarah & am also giving these 4 stars just because o...\n",
      "If, like me, you actively seek out the rarest and weirdest (and often most awful) that world cinema ...\n",
      "Wow. The storyline to this was just incredibly stupid. I realize that this movie was supposed to be ...\n",
      "I rented the DVD in a video store, as an alternative to reading the report. But it's pretty much jus...\n",
      "I am not sure who is having more fun, the people that wrote the reviews or the director of the movie...\n",
      "Here is a rundown of a typical Rachael Ray Show:<br /><br />1. The awful theme song begins to play, ...\n",
      "This film's a big bore. It has a plenty of Predictable plots & endless sentiments from the start. It...\n",
      "Despite a great soundtrack and the presence of the ever amazing Rappaport and Woods, this is another...\n",
      "Ed Wood, perhaps the worst film maker of all time left us gems that are SO bad, they delight, being ...\n",
      "This \"space snippet\" was kind of dumb. I guess it was supposed to be a shocker unexpected ending, bu...\n",
      "I'm guessing that the folks talking up this drivel are cronies of the director or something. This is...\n",
      "**** Possible Spoiler **** <br /><br />If you were making a serious movie involving a powerful, but ...\n",
      "I know we shouldn't expect much from a low-budget indie film. But the idea behind it is sound: an at...\n",
      "<br /><br />12 Grand is the cost of a new car. A new car that Jake West now needs to escape the hord...\n",
      "This good-guy-vs-the-evil-tyrant story, set in 19th century Russia, may have been an attempt to exte...\n",
      "The casting (and direction) in Undercurrent is more insipid than inspired in this noir clunker that ...\n",
      "The use of \"astral projection\"(wandering soul), to exist outside of body, with the result inflicting...\n",
      "I, like so many others on here, bought this movie at my local WM in the \"Two for $11.00\" cheap-o bin...\n",
      "Do the following: Get a copy of this movie and a friend. Wager the friend $10 that they can't sit th...\n",
      "Bad sequels.....this one's a real one! When the first movie was very very bad, you have to be fool t...\n",
      "This movie is very disappointing for one who has read the book. As written by Rafael Sabatini, this ...\n",
      "If you are a Christian or a Jew hoping to see an accurate Biblical (or Torah) portrayal of the event...\n",
      "Horrible, misogynist drivel. My neighbor brought this turkey over, subjected me to it, and didn't ha...\n",
      "I really wanted to like this movie, but the pacing was just way too slow.<br /><br />It was a nice s...\n",
      "i hired this movie out from my local movie shop, not really expecting anything to flash or fancy. Si...\n",
      "Cheerleader Massacre was supposed to be the fourth installment of the Slumber Party Massacre series;...\n",
      "This film really misses the mark on most fronts. The accents are laughably weak, the acting amateuri...\n",
      "waste of 1h45 this nasty little film is one to avoid, its like a cheap badly plotted cross between s...\n",
      "The Lifetime channel aired this in October but I only got around to watching it now. It's the old et...\n",
      "This is by far the most vapid, idiotic, insanely stupid show that has EVER been on the air, and this...\n",
      "I's a big struggle. As a story that is surreal, this movie could've been great (as great as it is ra...\n",
      "I loved the first \"American Graffiti\" with all my heart and soul that I considered it to be the best...\n",
      "I am ashamed to admit in public that I even held the cover of this movie once! This is an absolute r...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watched the director's cut last night...glad it was free rental, even a dollar would have been too m...\n",
      "An ex- informant of the East Germany finishes in Mexico like spy of a student group in 1971 in where...\n",
      "I was all ready to hate this but it turned out to be surprisingly tolerable - though the MTV-style o...\n",
      "I saw a screening of this movie last night. I had high expectations going into it, but was definitel...\n",
      "If you are like me and observed the original \"Benji\" phenomenon from afar, finally seeing the movie ...\n",
      "As a helpful warning for others, I believe \"Skeleton Man\" is actually worse than \"Raptor Island.\" I ...\n",
      "Dear Movie Director:<br /><br />In the future, when trying to create a sense of urgency, it might be...\n",
      "This film is about the worst I have seen in a very long time. Terence Stamp's talent is totally wast...\n",
      "How many English 101 student's versions of 1984 must America endure? \"Gosh, this is a great book, bu...\n",
      "Other reviews have talked about how frank this film is, especially in terms of male frontal nudity. ...\n",
      "Sure it is a new take on vampires. Who cares. I would rather the old take if it is entertaining. Thi...\n",
      "Stealing is a crime, and these guys, Kenny Yakkel and Corbin Bernsen look like their going to get aw...\n",
      "First things first - though I believe Joel Schumacher is at best a mediocre director and more often ...\n",
      "To sum it all up, skip End of Days and watch rent Roman Polanski's The Ninth Gate instead. This movi...\n",
      "If you never have read the book and never intend to read it in the future, go on and watch the movie...\n",
      "Well, for this abomination of a film, I wasn't expecting anything good. I find Steve Carell annoying...\n",
      "As Ben Elton once observed, nothing goes quicker out of style than comedy. Steve Martin's latest off...\n",
      "Before I really slag this film off, I just want to say I absolutely loved it. <br /><br />Firstly, h...\n",
      "If I heard the male lead say \"This is madness!\" one more time I would have barfed. The film is one b...\n",
      "I really enjoyed \"Candid camera\" with Dom DeLuise and I was surprised to see that after the years Su...\n",
      "This movie tries to be more than it is. First of all, the acting is horrible. You have to get past t...\n",
      "It's funny... one day before i have seen this movie i had been watching a documentary about Leni Rie...\n",
      "This movie was OK, as far as movies go. It could have been made as a crossover into secular movies. ...\n",
      "To be hones, I used to like this show and watch it regularly, but now (thank god!) I don't understan...\n",
      "Just saw Coronado... Around here the only line they came up with to sell it is \"from the FX team beh...\n",
      "**Could be considered some mild spoilers, but no more than in anyone else's review of this film.**<b...\n",
      "I'm not going to say too much as this movie isn't worth the effort. To put it simply the movie absol...\n",
      "This is one of the most laughably bad films I've ever seen. I cannot believe whoever wrote the revie...\n",
      "Apart from the beautiful imagery thanks to New Zealand cinematographer Alun Bollinger, this film is ...\n",
      "As one who loves films that appeal to intellectual sorties as well as those that simply tell stories...\n",
      "Camp Blood is an absolutely atrocious slasher film. We're mixing Friday The 13th with the Blair Witc...\n",
      "Because that's what Hell Ride pretty much is. Larry Bishop and Tarantino partying on the Weinstein's...\n",
      "This was okay, but really a bit disappointing because I expected more laughs. Considering the storyl...\n",
      "Up until around 1970 Lucille Ball was one great comedienne. She was such a perfect clown I only wish...\n",
      "The Evil that Men Do (1984) was one of the few non-Cannon films Charlie Bronson made during the 80's...\n",
      "*** This comment may contain spoilers *** Warning: this does contain spoilers I have seen some prett...\n",
      "I wish that all the mockumentaries and horror spoofs would go away. If you are going to investigate ...\n",
      "What can you say about a film that makes \"The Erotic Witch Project\" look like \"The English Patient.\"...\n",
      "First off, I refuse to even consider this piece of work a Music video... I consider it a short film ...\n",
      "Love the TPB's but this was a lame episode. Didn't have the same feel that the series or the movie h...\n",
      "This movie is so bad that it actually gets funny. One of the worst movies I've ever seen in my entir...\n",
      "As stated by others, this is a ludicrously horrible movie (NOT A FILM!). It is not bad in a funny wa...\n",
      "Screen treatment of the comedic Broadway success \"The Gay Divorce\" (a title which was considered too...\n",
      "The original WASC isn't by any means a must see movie in the genre. In fact, if it weren't for it's ...\n",
      "If I were to pitch this movie idea to some Hollywood bigwigs, I'm sure it would sound like this: <br...\n",
      "Meet Cosmo (Jason Priestley), a nerdy young bookie content with his boring life crunching numbers fo...\n",
      "Totally un-funny \"jokes\" that fall flat, amateurish acting (with one or two exceptions), boring char...\n",
      "I'm also a SF buff, among other genres, and I especially like those films from 60's and 70's with th...\n",
      "Five Fingers is so bad, that I hardly know where to begin. So let me admit first, that I have only s...\n",
      "If you would have asked me 1 month ago how this movie was I probably would have left most of this ou...\n",
      "While it has been many decades since I last read Mr. Wells \"War of the Worlds\", or \"The Time Machine...\n",
      "some funny lines are all what makes this movie bearable. the camera tv-movie-like, the acting poor (...\n",
      "I can only say this: ee03128 from Portugal, I couldn't say it better. The worst movie I've ever seen...\n",
      "I have a question for the writers and producers of \"Prozac Nation\": What is the root cause and what ...\n",
      "This movie should have ended as soon as the joke about Bebe's Kids is told in the opening. I liked R...\n",
      "The storyline of this movie is cliché and obviously has been ripped off from Jurassic Park. The film...\n",
      "It is very possible that I simply didn't give the movie a fair enough chance because it was so immed...\n",
      "I very well remember the bad press this film got because of the producers' court order against Clayt...\n",
      "I would bet a month's salary \"The Magnificent Seven Returns\" (MSR) was made-for-TV. Other reviewers ...\n",
      "The idea of nine stupid prisoners escaping and going on a road trip sounds pretty good for a movie. ...\n",
      "Just saw it....the story, the plot, the script makes absolute no sense!! Its Samvise the brave part ...\n",
      "The original Road House was a classic cheesy 80s movie, which although it didn't have anywhere near ...\n",
      "Like another reviewer, my wife bought this movie as part of a 20 movie family pack. I guess you coul...\n",
      "'The Shining' has wit, visual flair and an iconic performance by Jack Nicholson. 'Ausentes,' however...\n",
      "From the film's first shot - Keira Knightley as Elizabeth Bennet wandering reading through a field a...\n",
      "Pumpkinhead was in itself a decent 80s horror flick. No classic by any means, but an enjoyable piece...\n",
      "I awarded this presentation 4 stars. They are all for the script, which has been butchered beyond re...\n",
      "I think I win the \"bargain\" contest for this movie, since I got it as part of a \"Martial Arts Movie ...\n",
      "After watching the first movie in BCI's new Aztec Mummy Collection, it's difficult to believe how ex...\n",
      "I saw bits and pieces of this on TV once, and when a friend recommended it, I began looking for it e...\n",
      "I can't believe this movie is getting the rating that it is here on IMDb. Of course, I've come to co...\n",
      "When my Mum went down to the video store to rent a film for the night my sister and I learned a less...\n",
      "From the brilliant mind that brought us \"The Exorcist\"...and \"Cruising.\" \"Rampage\" is unfortunately ...\n",
      "The other reviewer was completely correct about this one. The writing was awful, the acting was awfu...\n",
      "absolutely nothing about this movie is funny, interesting, or relevant. besides two characters getti...\n",
      "I have seen many movies over the years and I am a big fan of comedies.<br /><br />But this so-called...\n",
      "Originally, the Spiders was planned as a four-part serial, and it shows. I dislike serials; they're ...\n",
      "This is a really bad waste of your time. I would probably rather go watch some documentary than this...\n",
      "Retro Puppet Master is complete and utter CRAP.In particular,the puppets look stupid,and crappy.The ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To put it simply, this was a pompous piece of canine poopie. Overly stagey and everyone being the to...\n",
      "An American Werewolf in London had some funny parts, but this one isn't so good. The computer werewo...\n",
      "The worst movie I've seen in a long time. This whole thing rings false, and the Billy Crudup charact...\n",
      "I expected a lot more out of this film. The preview looked interesting so I decided to check it out....\n",
      "I don't understand jokes. I do believe this is my problem with modern cinema, or those films that ar...\n",
      "I don't understand how some people can stand playing \"Half-Life: Counter-Strike\" when there are so m...\n",
      "Last time I checked, the Nazis didn't win the second world war - not that you'd sodding notice. Afte...\n",
      "...now please move on because that's getting on my nerves.<br /><br />Seriously, the man behind bril...\n",
      "Originally harped as a sequel to \"The Slumber Party Massacre\" series, this film falls flat on it's f...\n",
      "On the bright side, it ended. That's the only thing this movie has going for it, of course.<br /><br...\n",
      "*****SPOILERS*********<br /><br />This movie was truly awful. This woman deceives her employers righ...\n",
      "What an atrocity. I am not one to demand total verisimilitude from a movie, but the plot and screenp...\n",
      "The comments for Commune make it sound like a very interesting film, one that I would be deeply inte...\n",
      "After 15 minutes watching the movie I was asking myself what to do: leave the theater, sleep or try ...\n",
      "I don't know, but the movie was just too similar to other movies I've seen. The Ring, The Eye, Dark ...\n",
      "Of the thousands of movies I've seen so far, this is the first one which made me think of the \"waste...\n",
      "It's as if the Stay-Puffed Marshmallow Man from Ghostbusters had been reincarnated in Rutger Hauer's...\n",
      "Watching this movie, you just have to ask: What were they thinking? There are so many noticeably bad...\n",
      "I got subjected to this pile one Wednesday afternoon when my mother-in-law was watching it. I can't ...\n",
      "I love this movie. Even though I rated it a \"4\", that's because the acting, the plot and the budget ...\n",
      "If you have never read the classic science fiction novel this mini-series is based on, it may actual...\n",
      "Times I look back to high school and it amazes me that I never went lower than Marvin did in this BA...\n",
      "Normally I don't bother wasting my time writing comments for junk like this that I forget almost as ...\n",
      "Once again, I've been duped by seemingly intelligent reviews making seemingly intelligent comments a...\n",
      "This is by far the worst British comedy ever, how it made it past the first episode let alone the pi...\n",
      "I will admit I didn't pay full attention to everything going on in this film, but to be honest, I do...\n",
      "How do you make a totally unappealing movie out of a story by one of America's most famous authors? ...\n",
      "Bardem is great. Actresses are great. But Amenabar did not have to do it like this. It is OK that he...\n",
      "Dr. Marnie Bannister (Magda Konopka) is a horribly disfigured woman. When one of her colleagues disc...\n",
      "Exceptionally silly actioner with braindead leads in a story which would have suited a fill-in issue...\n",
      "Ordinarily, I wouldn't waste the time on reviewing a film like \"Human Pork Chop\" (the 2001 version, ...\n",
      "OK, I read the director's comment about this movie (featured as the 'frontmost comment'), and I have...\n",
      "This movie is at times a wild 80s college sex comedy, others a sweet romantic one... Then it has mom...\n",
      "Why did they not follow the book ... I am really sad and disappointed. I was so looking forward to s...\n",
      "I just finished watching one episode(S1-#5 A boy in a bush), so maybe my review is not very fair.<br...\n",
      "The movie opens with a scene that simply could not be. A man wakes up and while his wife remains in ...\n",
      "This is one of the worst movies EVER made. I can't believe how bad it was. I was shocked at the awfu...\n",
      "Dude...I liked Buffy and Angel as much as the next sci-fi freak...but this is too much. The worst le...\n",
      "In the mountains of Japan, forlorn young artist Sessue Hayakawa (as Tatsu aka \"The Dragon Painter\") ...\n",
      "Can there be a worst film? Even Ed Wood at his horrific worst couldn't come up with something this b...\n",
      "\"Curse of the Forty-Niner\" doesn't really deserve a long and detailed review, so I'll just make some...\n",
      "Dear reader, Watch out! This movie is not really a movie, though its creators have the impertinence ...\n",
      "This was one of the worst movies that I have ever watched. The story was about a woman prisoner sent...\n",
      "This tale of the upper-classes getting their come-uppance and wallowing in their high-class misery i...\n",
      "I have witnessed some atrocities of cinema. In the past couple of years, it seems producers and dire...\n",
      "I have seen most of John Waters' films. With the exception of several of his very early ones which a...\n",
      "It's painfully obvious that the people who made this \"movie\" have never seen such brilliant spoofs a...\n",
      "Final Draft - A screenwriter (James Van Der Beek) locks himself into his apartment and succumbs to p...\n",
      "It's dreadful, but ...<br /><br />Cat Stevens fans are given the opportunity to see the woman who in...\n",
      "This is truly one of the most awful movies of all time. It's dull, ponderous, badly acted, and teeth...\n",
      "Oh Gawd. I want to time travel back to Monogram Studios and throttle someone in their 2 room front o...\n",
      "Bad bad bad....<br /><br />This is another stupid movie. still don't know what is the language of th...\n",
      "The plot in Petites Coupures certainly left this viewer dumbfounded.<br /><br />***spoiler***<br /><...\n",
      "This is a piece of Hollywood product that should have never left a film can. Dialogue without a plau...\n",
      "These days, Asian horror films are among the best in the world, noted for their atmosphere and refle...\n",
      "... with a 500$ budget and a bottle of ketchup.<br /><br />If you are a fan of C movies with no tale...\n",
      "The filmmakers were clearly on drugs. That's the only explanation I have. How else do you explain th...\n",
      "Although the movie was only so so the closed captioning was by far the best I have ever seen! Most o...\n",
      "I guess this is in the public domain as its out on DVD. First off, this is a feel good propaganda mo...\n",
      "AVP2 is an awful movie. The dialogue was pointless, the acting was pathetic, it had virtually no sto...\n",
      "A mediocre at best horror flick that deals with dumb, not so horny teens who discover an evil video ...\n",
      "First of I should point out that I used to love Winnie The Pooh as a child and I really enjoyed The ...\n",
      "I am a big fan of British films in general but especially gangster movies. Unfortunately this film w...\n",
      "Very simply, they are all the syndicated episodes and NOT the original uncut/unedited NBC episodes. ...\n",
      "I really hoped for the best with this one, but it just didn't happen. Financed at a very non-dutch m...\n",
      "This movie is a waste of time. Though it has actors who have the potential to do something decent, t...\n",
      "This movie's basic premise is that everyone in the world can know that a person is gay except for th...\n",
      "I want very much to believe that the above quote (specifically, the English subtitle translation), w...\n",
      "Honestly, I didn't really have high expectations for this movie, but at the same time I was hopeful....\n",
      "Taste is a subjective thing. Two people can watch the same movie with one of them loving it and the ...\n",
      "Bill Rebane's \"The Capture of Bigfoot\" is one of the most awful horror movies ever made.A greedy saw...\n",
      "Although allegedly autobiographical, this movie demonstrates very little insight both into the prota...\n",
      "OH MY GOD! After having such a promising start, Critters 2 reiterated the Karmic rule of what goes a...\n",
      "I only came here to check Terror Hospital for an alternate title so I'd know what not to pick up. No...\n",
      "Another example of the women-in-prison genre. This is not exactly a genre known for quality films, b...\n",
      "Despite a totally misleading advertising campaign, this flick turns out to be an irritatingly cliché...\n",
      "This must be one of MGM's and FRANK SINATRAS worst films. An oddball musical comedy that fails in al...\n",
      "Cartoon-like special effects, horrible acting and dialogue, and dry plot! This movie has it all! My ...\n",
      "Luther the Geek (1990) is a dull horror movie and is really bad even by Troma's standards!! It's abo...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is by far the worst movie I have ever seen. What were they thinking. Stop preaching to me alrea...\n",
      "I wanted to see this movie because I liked \"Kavkazskij Plennik\" (\"Prisoner of the Mountains\") and \"B...\n",
      "I think Trash really sucks. I watched it a couple of weeks ago and I haven't seen that kind of c**p ...\n",
      "I enjoy gay-themed movies where the characters aren't stereotypically gay and that's what attracted ...\n",
      "I've always loved horror flicks. From some of the usual well-known like \"The Exorcist\" to some of th...\n",
      "Rented(free rental thank goodness) this as supposedly filmed in CT where I live....could have been f...\n",
      "This might very well be the worst movie I've seen in my life. Normally I don't watch movies like thi...\n",
      "This show, Paranormal State, has an almost \"Blairwitch Project\" feel to it. As in, you're watching a...\n",
      "I honestly don't know where to begin when reviewing a movie as pathetic as Ernest Goes to Africa. As...\n",
      "I can't remember when was the last time I have been so terribly disappointed by any movie. Probably ...\n",
      "Rutger Hauer helps along a film that basically can be summed up in the young person finding themselv...\n",
      "This film contain far too much meaningless violence. Too much shooting and blood. The acting seems v...\n",
      "The person who wrote the summary and rave review for this film is either an idiot or an avid fan of ...\n",
      "Breaker! Breaker! has Chuck Norris as a truck driver and a karate master, talk about juggling two di...\n",
      "Alas, another Costner movie that was an hour too long. Credible performances, but the script had no ...\n",
      "A young man, named Danny, has run away from home and meets a drifter, named Bix, who agrees to tag a...\n",
      "The premise of this film is the only thing worthwhile. It is very poorly made but the idea was cleve...\n",
      "Should I have expected anything other than putrid from Carrot Top? This was on of the worst movies I...\n",
      "Down at the Movie Gallery, I saw a flick I just had to see. It looked like a fun low-budget horror/a...\n",
      "This started out slow, then got worse. The best parts of this were all seen in the previews.<br /><b...\n",
      "You can generally ask two questions concerning 80's low-budget horror films. and this `Demon Wind' i...\n",
      "This movie (even calling it a movie is an overstatement) is ridiculously horrible. Normally a huge f...\n",
      "Yes sure, this is a Friday the 13th rip off but I have no problem with it. It's a good effort, the k...\n",
      "\"War is in your blood\" Rambo says early in the film, \"don't fight it\". Say, what? Is the scriptwrite...\n"
     ]
    }
   ],
   "source": [
    "ground, results = test_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ground, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an additional test, we can try sending the `test_review` that we looked at earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(test_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know our endpoint is working as expected, we can set up the web page that will interact with it. If you don't have time to finish the project now, make sure to skip down to the end of this notebook and shut down your endpoint. You can deploy it again when you come back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 (again): Use the model for the web app\n",
    "\n",
    "> **TODO:** This entire section and the next contain tasks for you to complete, mostly using the AWS console.\n",
    "\n",
    "So far we have been accessing our model endpoint by constructing a predictor object which uses the endpoint and then just using the predictor object to perform inference. What if we wanted to create a web app which accessed our model? The way things are set up currently makes that not possible since in order to access a SageMaker endpoint the app would first have to authenticate with AWS using an IAM role which included access to SageMaker endpoints. However, there is an easier way! We just need to use some additional AWS services.\n",
    "\n",
    "<img src=\"Web App Diagram.svg\">\n",
    "\n",
    "The diagram above gives an overview of how the various services will work together. On the far right is the model which we trained above and which is deployed using SageMaker. On the far left is our web app that collects a user's movie review, sends it off and expects a positive or negative sentiment in return.\n",
    "\n",
    "In the middle is where some of the magic happens. We will construct a Lambda function, which you can think of as a straightforward Python function that can be executed whenever a specified event occurs. We will give this function permission to send and recieve data from a SageMaker endpoint.\n",
    "\n",
    "Lastly, the method we will use to execute the Lambda function is a new endpoint that we will create using API Gateway. This endpoint will be a url that listens for data to be sent to it. Once it gets some data it will pass that data on to the Lambda function and then return whatever the Lambda function returns. Essentially it will act as an interface that lets our web app communicate with the Lambda function.\n",
    "\n",
    "### Setting up a Lambda function\n",
    "\n",
    "The first thing we are going to do is set up a Lambda function. This Lambda function will be executed whenever our public API has data sent to it. When it is executed it will receive the data, perform any sort of processing that is required, send the data (the review) to the SageMaker endpoint we've created and then return the result.\n",
    "\n",
    "#### Part A: Create an IAM Role for the Lambda function\n",
    "\n",
    "Since we want the Lambda function to call a SageMaker endpoint, we need to make sure that it has permission to do so. To do this, we will construct a role that we can later give the Lambda function.\n",
    "\n",
    "Using the AWS Console, navigate to the **IAM** page and click on **Roles**. Then, click on **Create role**. Make sure that the **AWS service** is the type of trusted entity selected and choose **Lambda** as the service that will use this role, then click **Next: Permissions**.\n",
    "\n",
    "In the search box type `sagemaker` and select the check box next to the **AmazonSageMakerFullAccess** policy. Then, click on **Next: Review**.\n",
    "\n",
    "Lastly, give this role a name. Make sure you use a name that you will remember later on, for example `LambdaSageMakerRole`. Then, click on **Create role**.\n",
    "\n",
    "#### Part B: Create a Lambda function\n",
    "\n",
    "Now it is time to actually create the Lambda function.\n",
    "\n",
    "Using the AWS Console, navigate to the AWS Lambda page and click on **Create a function**. When you get to the next page, make sure that **Author from scratch** is selected. Now, name your Lambda function, using a name that you will remember later on, for example `sentiment_analysis_func`. Make sure that the **Python 3.6** runtime is selected and then choose the role that you created in the previous part. Then, click on **Create Function**.\n",
    "\n",
    "On the next page you will see some information about the Lambda function you've just created. If you scroll down you should see an editor in which you can write the code that will be executed when your Lambda function is triggered. In our example, we will use the code below. \n",
    "\n",
    "```python\n",
    "# We need to use the low-level library to interact with SageMaker since the SageMaker API\n",
    "# is not available natively through Lambda.\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    # The SageMaker runtime is what allows us to invoke the endpoint that we've created.\n",
    "    runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "    # Now we use the SageMaker runtime to invoke our endpoint, sending the review we were given\n",
    "    response = runtime.invoke_endpoint(EndpointName = '**ENDPOINT NAME HERE**',    # The name of the endpoint we created\n",
    "                                       ContentType = 'text/plain',                 # The data format that is expected\n",
    "                                       Body = event['body'])                       # The actual review\n",
    "\n",
    "    # The response is an HTTP response whose body contains the result of our inference\n",
    "    result = response['Body'].read().decode('utf-8')\n",
    "\n",
    "    return {\n",
    "        'statusCode' : 200,\n",
    "        'headers' : { 'Content-Type' : 'text/plain', 'Access-Control-Allow-Origin' : '*' },\n",
    "        'body' : result\n",
    "    }\n",
    "```\n",
    "\n",
    "Once you have copy and pasted the code above into the Lambda code editor, replace the `**ENDPOINT NAME HERE**` portion with the name of the endpoint that we deployed earlier. You can determine the name of the endpoint using the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-pytorch-2019-11-09-05-49-01-067'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have added the endpoint name to the Lambda function, click on **Save**. Your Lambda function is now up and running. Next we need to create a way for our web app to execute the Lambda function.\n",
    "\n",
    "### Setting up API Gateway\n",
    "\n",
    "Now that our Lambda function is set up, it is time to create a new API using API Gateway that will trigger the Lambda function we have just created.\n",
    "\n",
    "Using AWS Console, navigate to **Amazon API Gateway** and then click on **Get started**.\n",
    "\n",
    "On the next page, make sure that **New API** is selected and give the new api a name, for example, `sentiment_analysis_api`. Then, click on **Create API**.\n",
    "\n",
    "Now we have created an API, however it doesn't currently do anything. What we want it to do is to trigger the Lambda function that we created earlier.\n",
    "\n",
    "Select the **Actions** dropdown menu and click **Create Method**. A new blank method will be created, select its dropdown menu and select **POST**, then click on the check mark beside it.\n",
    "\n",
    "For the integration point, make sure that **Lambda Function** is selected and click on the **Use Lambda Proxy integration**. This option makes sure that the data that is sent to the API is then sent directly to the Lambda function with no processing. It also means that the return value must be a proper response object as it will also not be processed by API Gateway.\n",
    "\n",
    "Type the name of the Lambda function you created earlier into the **Lambda Function** text entry box and then click on **Save**. Click on **OK** in the pop-up box that then appears, giving permission to API Gateway to invoke the Lambda function you created.\n",
    "\n",
    "The last step in creating the API Gateway is to select the **Actions** dropdown and click on **Deploy API**. You will need to create a new Deployment stage and name it anything you like, for example `prod`.\n",
    "\n",
    "You have now successfully set up a public API to access your SageMaker model. Make sure to copy or write down the URL provided to invoke your newly created public API as this will be needed in the next step. This URL can be found at the top of the page, highlighted in blue next to the text **Invoke URL**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Deploying our web app\n",
    "\n",
    "Now that we have a publicly available API, we can start using it in a web app. For our purposes, we have provided a simple static html file which can make use of the public api you created earlier.\n",
    "\n",
    "In the `website` folder there should be a file called `index.html`. Download the file to your computer and open that file up in a text editor of your choice. There should be a line which contains **\\*\\*REPLACE WITH PUBLIC API URL\\*\\***. Replace this string with the url that you wrote down in the last step and then save the file.\n",
    "\n",
    "Now, if you open `index.html` on your local computer, your browser will behave as a local web server and you can use the provided site to interact with your SageMaker model.\n",
    "\n",
    "If you'd like to go further, you can host this html file anywhere you'd like, for example using github or hosting a static site on Amazon's S3. Once you have done this you can share the link with anyone you'd like and have them play with it too!\n",
    "\n",
    "> **Important Note** In order for the web app to communicate with the SageMaker endpoint, the endpoint has to actually be deployed and running. This means that you are paying for it. Make sure that the endpoint is running when you want to use the web app but that you shut it down when you don't need it, otherwise you will end up with a surprisingly large AWS bill.\n",
    "\n",
    "**TODO:** Make sure that you include the edited `index.html` file in your project submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your web app is working, trying playing around with it and see how well it works.\n",
    "\n",
    "**Question**: Give an example of a review that you entered into your web app. What was the predicted sentiment of your example review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Input: I like the movie but my friends dislike it and my family dislikes it too. In fact, everybody I know dislikes it.\n",
    "\n",
    "Output: Positive. The model seems to not learn to associate the word dislike with a negative outcome. This also might be because the word \"dislike\" does not exist in our training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the endpoint\n",
    "\n",
    "Remember to always shut down your endpoint if you are no longer using it. You are charged for the length of time that the endpoint is running so if you forget and leave it on you could end up with an unexpectedly large bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
